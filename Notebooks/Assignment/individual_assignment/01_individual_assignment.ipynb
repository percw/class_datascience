{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795860f2-eabf-40d1-954c-843dcf672a7d",
   "metadata": {},
   "source": [
    "# MGT-499 Statistics and Data Science - Individual Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a58faf4-db28-41c1-9e6d-ead96d328eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here what you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5761d-3238-4e69-951f-6fea4557ef41",
   "metadata": {},
   "source": [
    "This notebook contains the individual assignment for the class MGT-499 Statistics and Data Science. Important information:\n",
    "- **Content**: the assignment is divided in two main parts, namely data cleaning (2 datasets) and Exploratory Data Analysis, for a total of 13 main questions (see table of contents). Some of these main questions are divided in sub questions. In the first part, the questions are very specific, while in the second part they are more open.\n",
    "- **Deadline**: Tuesday 8th of November at 23:59. \n",
    "- **Final Output**: a Jupyter notebook, which we (teachers) can run. \n",
    "- **Answering the Questions**: you will find the questions in markdown cells below. Under each of these cells, you will find a cell / cells for answers. Type there your answer. For the answer to be correct, the cell with the answer must run without error (unless specified). You can use markdown cells for the answers that require text.\n",
    "- **Submission**: submit the assignment on Moodle, under [Individual Assignment](https://moodle.epfl.ch/mod/assign/view.php?id=1222846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43ccf-9ed6-44ea-8dd3-184cb9e7c499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Content\n",
    "- [Polity5 Dataset](#polity5)  \n",
    "    - [Question 1: Import the data and get a first glance](#question1)\n",
    "    - [Question 2: Select some variables](#question2)\n",
    "    - [Question 3: Missing Values](#question3)\n",
    "    - [Question 4: Check Polity2](#question4)\n",
    "- [Quality of Government (QOG) Environmental Indicators Dataset](#qog)  \n",
    "    - [Question 5: Import the data and do few fixes](#question5)\n",
    "    - [Question 6: Merge QOG and Polity5 ... first attempt](#question6)\n",
    "    - [Question 7: Merge QOG and Polity5 ... second attempt](#question7)\n",
    "    - [Question 8: Clean the merged dataframe](#question8)\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "    - [Question 9: Selecting the ingredients for the recipe (how I select the variables)](#question9)  \n",
    "    - [Question 10: Picking the right quantity of each ingredient (how I select my sample)](#question10)\n",
    "    - [Question 11: Tasting and preparing the ingredients (univariate analysis)](#question11)\n",
    "    - [Question 12: Cooking the ingredients together (bivariate analysis)](#question12)\n",
    "    - [Question 13: Tasting the new recipe (conclusion)](#question13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142f738-6239-4e12-9c65-fd27b4db73ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polity5 data <a class=\"anchor\" id=\"polity5\"></a>\n",
    "\n",
    "Polity5 is a widely used democracy scale. The raw data as well as the codebook are available [here](http://www.systemicpeace.org/inscrdata.html). For this assignment, we have modified a bit the original version, for example we have added the iso3 code for countries to make you save time. You can find the modified version [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903da7f-480e-4777-a4ef-9ab94b09e473",
   "metadata": {},
   "source": [
    "### Question 1: import the data and get a first glance <a class=\"anchor\" id=\"question1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f6829-6c8f-451a-9670-4d1c7a103c12",
   "metadata": {},
   "source": [
    "1a) Import the csv 'polity2_iso3.csv' (file provided in the link [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)) as a panda dataframe (ignore the warning message) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee7e4014-e55c-4994-a633-61a8fdf1e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1a\n",
    "\n",
    "polity_data = pd.read_csv('https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd738c61-10ca-4439-8bcf-20e6987e3e5f",
   "metadata": {},
   "source": [
    "1b) Display the first 10 rows **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10544e0c-33b5-4b90-ad68-4cfe8d6c40b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3</th>\n",
       "      <th>year</th>\n",
       "      <th>p5</th>\n",
       "      <th>cyear</th>\n",
       "      <th>ccode</th>\n",
       "      <th>scode</th>\n",
       "      <th>country</th>\n",
       "      <th>flag</th>\n",
       "      <th>fragment</th>\n",
       "      <th>democ</th>\n",
       "      <th>...</th>\n",
       "      <th>interim</th>\n",
       "      <th>bmonth</th>\n",
       "      <th>bday</th>\n",
       "      <th>byear</th>\n",
       "      <th>bprec</th>\n",
       "      <th>post</th>\n",
       "      <th>change</th>\n",
       "      <th>d5</th>\n",
       "      <th>sf</th>\n",
       "      <th>regtrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>2711800</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>7301800</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>2451800</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>7301801</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>2711801</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>2451801</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>7301802</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>2711802</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>2451802</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1803</td>\n",
       "      <td>0</td>\n",
       "      <td>7301803</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso3  year  p5    cyear  ccode scode       country  flag  fragment  democ  \\\n",
       "0  NaN  1800   0  2711800    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "1  NaN  1800   0  7301800    730   KOR         Korea     0       NaN      5   \n",
       "2  NaN  1800   0  2451800    245   BAV       Bavaria     0       NaN      0   \n",
       "3  NaN  1801   0  7301801    730   KOR         Korea     0       NaN      5   \n",
       "4  NaN  1801   0  2711801    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "5  NaN  1801   0  2451801    245   BAV       Bavaria     0       NaN      0   \n",
       "6  NaN  1802   0  7301802    730   KOR         Korea     0       NaN      5   \n",
       "7  NaN  1802   0  2711802    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "8  NaN  1802   0  2451802    245   BAV       Bavaria     0       NaN      0   \n",
       "9  NaN  1803   0  7301803    730   KOR         Korea     0       NaN      5   \n",
       "\n",
       "   ...  interim  bmonth  bday byear  bprec  post  change   d5   sf  regtrans  \n",
       "0  ...      NaN       1     1  1800      1    -7      88    1  NaN       NaN  \n",
       "1  ...      NaN       1     1  1800      1     1      88    1  NaN       NaN  \n",
       "2  ...      NaN       1     1  1800      1   -10      88    1  NaN       NaN  \n",
       "3  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "4  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "5  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "6  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "7  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "8  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "9  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 1b\n",
    "polity_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6decfca-afb8-4c77-881c-8fb78d96e68d",
   "metadata": {},
   "source": [
    "1c) Display the data types of all the variables included in the data **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa768541-03f9-424a-a690-d6132298f36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iso3</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p5</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyear</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccode</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scode</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragment</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democ</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autoc</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polity</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polity2</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>durable</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xrreg</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xrcomp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xropen</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xconst</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parreg</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcomp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exrec</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exconst</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polcomp</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emonth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eday</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyear</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eprec</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interim</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmonth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bday</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byear</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bprec</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regtrans</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "iso3       object\n",
       "year        int64\n",
       "p5          int64\n",
       "cyear       int64\n",
       "ccode       int64\n",
       "scode      object\n",
       "country    object\n",
       "flag        int64\n",
       "fragment  float64\n",
       "democ       int64\n",
       "autoc       int64\n",
       "polity      int64\n",
       "polity2   float64\n",
       "durable    object\n",
       "xrreg       int64\n",
       "xrcomp      int64\n",
       "xropen      int64\n",
       "xconst      int64\n",
       "parreg      int64\n",
       "parcomp     int64\n",
       "exrec     float64\n",
       "exconst     int64\n",
       "polcomp   float64\n",
       "prior      object\n",
       "emonth     object\n",
       "eday       object\n",
       "eyear      object\n",
       "eprec      object\n",
       "interim    object\n",
       "bmonth     object\n",
       "bday       object\n",
       "byear      object\n",
       "bprec      object\n",
       "post       object\n",
       "change     object\n",
       "d5         object\n",
       "sf         object\n",
       "regtrans   object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 1c\n",
    "data_type  = polity_data.dtypes\n",
    "data_type.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ee31a-7cc9-44d2-b7f8-242f6ee5ebfc",
   "metadata": {},
   "source": [
    "1d) By looking at your answer in 1c, what is the difference between the different types of variables? Why the type of some variables is defined as object? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97f628-71b6-4aac-9c9c-596773557131",
   "metadata": {},
   "source": [
    "Answer 1d:\n",
    "\n",
    "We can see that we have four different dataypes: `object`, `float64` and `int64`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfba84f-b897-4fcb-880d-9d8995045239",
   "metadata": {},
   "source": [
    "### Question 2. Select some variables <a class=\"anchor\" id=\"question2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9776a-26ed-4154-af73-0e2b337e9e74",
   "metadata": {},
   "source": [
    "2a) Create a subset dataframe that contains the variables 'iso3', 'country', 'year', 'polity2' and display it **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3bd0a39-386d-4397-93eb-8eb7e0415a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2a\n",
    "polity_data_subset = (polity_data[['iso3', 'country', 'year', 'polity2']]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4883d-8f9e-4b1f-9ce4-c62267090287",
   "metadata": {},
   "source": [
    "2b) Display the type of the variable \"year\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0dc6b73-70d9-42c0-9cd1-716033325a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2b\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639b2d3-b5e6-40f3-93c9-6547bcdcb814",
   "metadata": {},
   "source": [
    "2c) Convert the variable \"year\" to string **(1 point)**\n",
    "<br>\n",
    "Hint: if you get a warning message of the type \"SettingWithCopyWarning\", it is because you did not subset the data in the right way. Go back to your class notes and check the different ways to subset a dataframe, and try again. If you do it correctly, you will not get the warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "914d8f60-9875-40be-9f78-0c7c2837a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "string[python]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2c\n",
    "polity_data_subset['year'] = polity_data_subset['year'].astype('string')\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0babf3-0e33-4e13-9289-523ecef5e004",
   "metadata": {},
   "source": [
    "### Question 3: Missing Values <a class=\"anchor\" id=\"question3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb19a0f-bd7c-4d9c-bdfa-05e55e4eb26f",
   "metadata": {},
   "source": [
    "3a) Subset the rows that have iso3 missing and display **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7eb48bb3-a92a-4565-8a5c-f22f642f2661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "         ...  \n",
       "17569    False\n",
       "17570    False\n",
       "17571    False\n",
       "17572    False\n",
       "17573    False\n",
       "Name: iso3, Length: 17574, dtype: bool"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3a\n",
    "iso_missing = polity_data_subset['iso3'].isna()\n",
    "\n",
    "# The rows with `True`` are 'NaN' values\n",
    "iso_missing\n",
    "\n",
    "#polity_data_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b352b-c860-4b2c-bca3-5437c2bbaf23",
   "metadata": {},
   "source": [
    "3b) Display the countries that have missing iso3. What can you tell by looking at them? Any similarities? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7e9760a-a4a6-4826-b377-49ff300662f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They seem to be old countries, or old country names.\n",
      "['Wuerttemburg' 'Korea' 'Bavaria' 'Saxony' 'Parma' 'Tuscany' 'Sardinia'\n",
      " 'Modena' 'Two Sicilies' 'Baden' 'Gran Colombia' 'United Province CA'\n",
      " 'Serbia' 'Orange Free State' 'Yemen North' 'Czechoslovakia' 'USSR'\n",
      " 'Germany West' 'Germany East' 'Pakistan' 'South Vietnam' 'Yemen South'\n",
      " 'Vietnam' 'Yugoslavia' 'Ethiopia' 'Serbia and Montenegro' 'Montenegro'\n",
      " 'Sudan-North']\n"
     ]
    }
   ],
   "source": [
    "# Answer 3b\n",
    "iso_missing_contries = polity_data_subset[polity_data_subset['iso3'].isna()]['country']\n",
    "print(f'They seem to be old countries, or old country names.\\n{iso_missing_contries.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41b9a2-2c70-41c6-b891-95e01f2a74a5",
   "metadata": {},
   "source": [
    "3c) Display the countries with missing iso3 from 2011. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b408fff2-6493-4dff-9294-ef1c564315fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethiopia', 'Montenegro', 'Serbia', 'Sudan-North', 'Vietnam']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3c\n",
    "# Interpreting the question so that we take the contries missing iso3 from 2011 onwards\n",
    "global df_missing_iso3_2011\n",
    "global sorted_df_clean_list\n",
    "\n",
    "df_missing_iso3_2011 = polity_data_subset[(polity_data_subset['iso3'].isna()) & (polity_data_subset['year'] >= '2011')]\n",
    "sorted_df_clean_list = sorted(df_missing_iso3_2011['country'].unique())\n",
    "sorted_df_clean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9a6b6-2151-4c5e-8a8a-ea9810905642",
   "metadata": {},
   "source": [
    "3d) Display the rows for which the column \"country\" contains the word \"Serbia\". By looking at the result, can you tell what happened to Serbia in 2006? **(1 point)**\n",
    "<br>\n",
    "Hint: the most general way of doing this is to use a combination of re.search and list comprehension. To display the full subset, you can use print(df.to_string())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a953ca64-d67b-4c94-8df6-5077efa68814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iso3 country  year  polity2\n",
      "224   NaN  Serbia  1830     -7.0\n",
      "230   NaN  Serbia  1831     -7.0\n",
      "252   NaN  Serbia  1832     -7.0\n",
      "261   NaN  Serbia  1833     -7.0\n",
      "272   NaN  Serbia  1834     -7.0\n",
      "286   NaN  Serbia  1835     -7.0\n",
      "295   NaN  Serbia  1836     -7.0\n",
      "301   NaN  Serbia  1837     -7.0\n",
      "318   NaN  Serbia  1838      2.0\n",
      "333   NaN  Serbia  1839      2.0\n",
      "344   NaN  Serbia  1840      2.0\n",
      "357   NaN  Serbia  1841      2.0\n",
      "363   NaN  Serbia  1842      2.0\n",
      "369   NaN  Serbia  1843      2.0\n",
      "387   NaN  Serbia  1844      2.0\n",
      "394   NaN  Serbia  1845      2.0\n",
      "410   NaN  Serbia  1846      2.0\n",
      "420   NaN  Serbia  1847      2.0\n",
      "429   NaN  Serbia  1848      2.0\n",
      "439   NaN  Serbia  1849      2.0\n",
      "450   NaN  Serbia  1850      2.0\n",
      "467   NaN  Serbia  1851      2.0\n",
      "475   NaN  Serbia  1852      2.0\n",
      "482   NaN  Serbia  1853      2.0\n",
      "492   NaN  Serbia  1854      2.0\n",
      "502   NaN  Serbia  1855      2.0\n",
      "523   NaN  Serbia  1856      2.0\n",
      "533   NaN  Serbia  1857      2.0\n",
      "542   NaN  Serbia  1858     -9.0\n",
      "553   NaN  Serbia  1859     -9.0\n",
      "572   NaN  Serbia  1860     -4.0\n",
      "575   NaN  Serbia  1861      0.0\n",
      "583   NaN  Serbia  1862      0.0\n",
      "593   NaN  Serbia  1863      0.0\n",
      "601   NaN  Serbia  1864      0.0\n",
      "608   NaN  Serbia  1865      0.0\n",
      "611   NaN  Serbia  1866      0.0\n",
      "623   NaN  Serbia  1867      0.0\n",
      "628   NaN  Serbia  1868     -3.0\n",
      "637   NaN  Serbia  1869     -5.0\n",
      "642   NaN  Serbia  1870     -5.0\n",
      "651   NaN  Serbia  1871     -5.0\n",
      "652   NaN  Serbia  1872     -5.0\n",
      "657   NaN  Serbia  1873     -5.0\n",
      "660   NaN  Serbia  1874     -5.0\n",
      "663   NaN  Serbia  1875     -5.0\n",
      "665   NaN  Serbia  1876     -5.0\n",
      "669   NaN  Serbia  1877     -5.0\n",
      "671   NaN  Serbia  1878     -5.0\n",
      "673   NaN  Serbia  1879     -5.0\n",
      "676   NaN  Serbia  1880     -5.0\n",
      "680   NaN  Serbia  1881     -5.0\n",
      "684   NaN  Serbia  1882     -5.0\n",
      "686   NaN  Serbia  1883     -5.0\n",
      "690   NaN  Serbia  1884     -5.0\n",
      "693   NaN  Serbia  1885     -5.0\n",
      "694   NaN  Serbia  1886     -5.0\n",
      "697   NaN  Serbia  1887     -5.0\n",
      "700   NaN  Serbia  1888     -5.0\n",
      "704   NaN  Serbia  1889     -5.0\n",
      "708   NaN  Serbia  1890     -5.0\n",
      "709   NaN  Serbia  1891     -5.0\n",
      "714   NaN  Serbia  1892     -5.0\n",
      "715   NaN  Serbia  1893     -5.0\n",
      "718   NaN  Serbia  1894     -5.0\n",
      "722   NaN  Serbia  1895     -5.0\n",
      "724   NaN  Serbia  1896     -5.0\n",
      "729   NaN  Serbia  1897     -5.0\n",
      "730   NaN  Serbia  1898     -5.0\n",
      "733   NaN  Serbia  1899     -5.0\n",
      "737   NaN  Serbia  1900     -5.0\n",
      "739   NaN  Serbia  1901     -5.0\n",
      "743   NaN  Serbia  1902     -5.0\n",
      "745   NaN  Serbia  1903      4.0\n",
      "748   NaN  Serbia  1904      4.0\n",
      "749   NaN  Serbia  1905      4.0\n",
      "751   NaN  Serbia  1906      4.0\n",
      "753   NaN  Serbia  1907      4.0\n",
      "755   NaN  Serbia  1908      4.0\n",
      "758   NaN  Serbia  1909      4.0\n",
      "759   NaN  Serbia  1910      4.0\n",
      "761   NaN  Serbia  1911      4.0\n",
      "762   NaN  Serbia  1912      4.0\n",
      "763   NaN  Serbia  1913      4.0\n",
      "764   NaN  Serbia  1914      4.0\n",
      "765   NaN  Serbia  1915      NaN\n",
      "766   NaN  Serbia  1916      NaN\n",
      "767   NaN  Serbia  1917      4.0\n",
      "769   NaN  Serbia  1918      5.0\n",
      "773   NaN  Serbia  1919      6.0\n",
      "774   NaN  Serbia  1920      7.0\n",
      "1213  NaN  Serbia  2006      8.0\n",
      "1217  NaN  Serbia  2007      8.0\n",
      "1218  NaN  Serbia  2008      8.0\n",
      "1224  NaN  Serbia  2009      8.0\n",
      "1228  NaN  Serbia  2010      8.0\n",
      "1231  NaN  Serbia  2011      8.0\n",
      "1238  NaN  Serbia  2012      8.0\n",
      "1247  NaN  Serbia  2013      8.0\n",
      "1248  NaN  Serbia  2014      8.0\n",
      "1254  NaN  Serbia  2015      8.0\n",
      "1263  NaN  Serbia  2016      8.0\n",
      "1269  NaN  Serbia  2017      8.0\n",
      "1276  NaN  Serbia  2018      8.0\n"
     ]
    }
   ],
   "source": [
    "# Answer 3d\n",
    "\n",
    "# It is important to check for varieties of capilized firstletter when using case sensitive comparison. Information may be lost. Here all country instances uses first capital letter.\n",
    "polity_data_subset_serbia = polity_data_subset[polity_data_subset['country'] == 'Serbia']\n",
    "print(polity_data_subset_serbia.to_string())\n",
    "\n",
    "# We can see that the country referred to as Serbia, reappeared in 2006, this is due to a name change following Montenegro and Serbias decleration of independence of their previous union named `State Union of Serbia and Montenegro`, previously called `Federal Republic of Yugoslavia``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd97b-0aaa-4bca-affb-22f3c0ca387c",
   "metadata": {},
   "source": [
    "3e) Write a function that does the operation in 3d and use it to display the subset that has the word \"sudan\" (all lower cap) in country. Then do the same for the word \"vietnam\" (all lower cap). **(1 point)**\n",
    "<br>\n",
    "Hint: options of functions can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3217b330-72ef-4d38-8a66-1849d12f7dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [iso3, country, year, polity2]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [iso3, country, year, polity2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Answer 3e\n",
    "def find_country(df:pd.DataFrame, country:str):\n",
    "\ttry:\n",
    "\t\treturn df[df['country'] == country]\n",
    "\texcept TypeError as e:\n",
    "\t\tprint(f'Not a valid datatype: {e}.\\nUse {pd.DataFrame} and {str} as option type parameters')\n",
    "\n",
    "df_sudan = find_country(polity_data_subset, 'sudan')\n",
    "df_vietnam = find_country(polity_data_subset, 'vietnam')\n",
    "\n",
    "print(df_sudan)\n",
    "print(df_vietnam)\n",
    "\n",
    "# Both empty. No country uses lower all low cap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a0adc-6104-4dff-baa4-cbc8259183b4",
   "metadata": {},
   "source": [
    "3f) Replace nan values in iso3 with correct iso3 for the 5 countries found in 3c from 2011 onwards, and display the subset with the fixed values to check that everything worked. **(1 point)**\n",
    "<br>\n",
    "Hint: the correct iso3 for these 5 countries are \"ETH\",\"MNE\",\"SRB\",\"SDN\",\"VNM\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "72ab9532-5a03-46fe-9db7-170e8b087957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.,   1., -10.,  nan,  -9.,  -4.,  -6.,  -1.,   2.,  -5.,  -8.,\n",
       "         4.,   0.,  -3.,   5.,   7.,   6.,  10.,   8.,  -2.,   9.,   3.,\n",
       "       -88., -66.])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3f\n",
    "\n",
    "# Storing the correct iso3 values in a list\n",
    "iso3_code_missing = ('ETH', 'MNE', 'SRB', 'SDN', 'VNM')\n",
    "\n",
    "# Creating a dict to look up correct iso3 values with list from 3c\n",
    "iso3_dict = dict(zip(sorted_df_clean_list, iso3_code_missing))\n",
    "\n",
    "# Defining a function to do repeated tasks\n",
    "def replace(df, dct, replaced):\t\n",
    " \tfor key, item in dct.items():\n",
    " \t\tdf.loc[(df['country'] == key) & (df['year'] >= '2011')] = df[(df['country'] == key) & (df['year'] >= '2011')].replace(replaced, item)\n",
    "\n",
    "# Calling the function and telling which value i want to replace\n",
    "replace(polity_data_subset, iso3_dict, np.nan)\n",
    "\n",
    "# Using the indexes of the subset created in 3c\n",
    "polity_data_subset.iloc[df_missing_iso3_2011.index]\n",
    "\n",
    "polity_data_subset.polity2.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa210c-b46f-46ff-a8da-d72d95bff196",
   "metadata": {},
   "source": [
    "3g) Drop the remaining rows which have nan in \"iso3\" and display the new number of rows of the dataframe (how many are they?) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c2cea78-0af1-405f-aeed-41dfc8fee4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16344"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3g\n",
    "\n",
    "# Subset with all NaNs in the iso3 column\n",
    "subset_with_remaining_nans = polity_data_subset[polity_data_subset['iso3'].isna()]\n",
    "\n",
    "# Indexes with NaN stored\n",
    "nans_indexes = subset_with_remaining_nans.index\n",
    "\n",
    "# Dropping row indexes with NaN\n",
    "df_clean = polity_data_subset.drop(index=nans_indexes)\n",
    "\n",
    "# Number of rows\n",
    "len(df_clean.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dc318-2264-4e42-8ca3-f1cf5b85fac5",
   "metadata": {},
   "source": [
    "### Question 4: Check Polity2 <a class=\"anchor\" id=\"question4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d643-6867-4c1c-93f9-c3c38fb9d454",
   "metadata": {},
   "source": [
    "4a) Display the first and last year included in the dataset **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57202c70-fe45-4f45-a29b-6a4761421972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1800\n",
      "17573    2018\n",
      "Name: year, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Answer 4a\n",
    "\n",
    "# Assuming the assignment is asking for the first and last of the original dataset\n",
    "print(polity_data_subset.iloc[[0,-1]]['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4593d98-be9b-45b3-86df-82e613ee851b",
   "metadata": {},
   "source": [
    "4b) What do the values in \"polity2\" represent? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4ecc-c2e6-4150-bf91-86bc067fd4a7",
   "metadata": {},
   "source": [
    "Answer 4b: \n",
    "\n",
    "`Polity2` is a revised version of the Polity score, which captures a regime authority on a `21-point` scale ranging from `-10` (hereditary monarchy) to `10` (consolidated democracy). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a9072-8271-4336-9219-3c64a3f16e07",
   "metadata": {},
   "source": [
    "4c) Do we have weird values for polity2? If yes, why? What should we do about them? Transform the data accordingly. **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e710121-c355-4f34-8f81-187ccee789b7",
   "metadata": {},
   "source": [
    "Answer 4c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef40f8d3-e7bd-49b9-9faa-a76931d0f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso3         0\n",
      "country      0\n",
      "year         0\n",
      "polity2    233\n",
      "dtype: int64\n",
      "[  9.   8.   0.  -3.  -4.  -7.   1.  -6.  -8. -10.  -1.  -2.  -9.  -5.\n",
      "   3.   5.   7.   2.   6.  10.   4. -88. -66.]\n",
      "[  9.   8.   0.  -3.  -4.  -7.   1.  -6.  -8. -10.  -1.  -2.  -9.  -5.\n",
      "   3.   5.   7.   2.   6.  10.   4.]\n"
     ]
    }
   ],
   "source": [
    "# Answer 4c\n",
    "\n",
    "# We have NaNs in polity2\n",
    "# Since we know that the NaNs from polity2 are the only ones left, we can just drop all NaNs.\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "df_cleaned = df_clean.dropna()\n",
    "\n",
    "# In addition we can see that we have values of -88 and -66. As this scale is supposed to range from -10 to 10, we should remove these as well.\n",
    "print(df_cleaned['polity2'].unique())\n",
    "\n",
    "# Lets find the rows of those values\n",
    "polity66 = df_cleaned[df_cleaned['polity2'] == -66].index\n",
    "polity88 = df_cleaned[df_cleaned['polity2'] == -88].index\n",
    "\n",
    "df_cleaned = df_cleaned.drop(index=polity66)\n",
    "df_cleaned = df_cleaned.drop(index=polity88)\n",
    "\n",
    "# Now we can see that we have the right values\n",
    "print(df_cleaned['polity2'].unique())\n",
    "\n",
    "# I can see that we have messed up the sorting of the data_frame. We can resolve this by using the sort_value function\n",
    "\n",
    "df_cleaned = df_cleaned.sort_values(['country', 'year']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b6f3a-11d9-477f-9fab-f7e644176c67",
   "metadata": {},
   "source": [
    "4d) Make a map that shows the number of observations of polity2 by country **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "53846332-57ef-4909-8367-5ffd2d737eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>polity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Vietnam North</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Yugoslavia</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  polity2\n",
       "0      Afghanistan      196\n",
       "1          Albania      105\n",
       "2          Algeria       57\n",
       "3           Angola       44\n",
       "4        Argentina      194\n",
       "..             ...      ...\n",
       "169  Vietnam North       23\n",
       "170          Yemen       29\n",
       "171     Yugoslavia       71\n",
       "172         Zambia       55\n",
       "173       Zimbabwe       39\n",
       "\n",
       "[174 rows x 2 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 4d\n",
    "\n",
    "pol_obs_per_country = df_cleaned.groupby(['country'])['polity2'].agg('count').reset_index()\n",
    "pol_obs_per_country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5258b-9ef6-4e9d-bf52-29a0d7ebc9b7",
   "metadata": {},
   "source": [
    "4e) Store the final dataframe (the one you obtained after 5d) in an object called df_pol **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7bb74cbc-5356-4e4b-b5b4-a5174c9ced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4e\n",
    "df_pol = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b6cd3-101d-4343-b76d-d97583fe33ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality of Government Environmental Indicators <a class=\"anchor\" id=\"qog\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58204e-f401-4b6e-b64a-c9d098faa0f2",
   "metadata": {},
   "source": [
    "The QoG Environmental Indicators dataset (QoG-EI) (Povitkina, Marina, Natalia Alvarado Pachon & Cem Mert Dalli. 2021). The Quality of Government Environmental Indicators Dataset, version Sep21. University of Gothenburg: The Quality of Government Institute, https://www.gu.se/en/quality-government), is a compilation of indicators measuring countries' environmental performance over time, including the presence and stringency of environmental policies, environmental outcomes (emissions, deforestation, etc.), and public opinion on the environment. Codebook and data are available [here](https://www.gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc77f2-25d1-41ce-930a-c25a05ac9cdc",
   "metadata": {},
   "source": [
    "### Question 5: Import the data and do few fixes <a class=\"anchor\" id=\"question5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959796a-3340-4231-838c-a4e2cba4262c",
   "metadata": {},
   "source": [
    "5a) Import data from the Quality of Government Environmental Indicators Dataset and display the variables types and the number of rows **(1 point)**\n",
    "<br>\n",
    "Hint: When you go on the webpage of the Environmental Indicators Dataset, you can directly import from a URL by copying the link address of the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "501ef767-dca9-426e-9e34-1335038b3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5a\n",
    "df_qog = pd.read_csv('data/qog_ei_sept21.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a8293-d098-4a79-a803-50d52f6b63b3",
   "metadata": {},
   "source": [
    "5b) Rename the variable \"ccodealp\" to \"iso3\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc0e78d3-06b3-418c-81b8-05bbef009ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5b\n",
    "df_qog.rename(columns={'ccodealp': 'iso3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b34e8-0daa-4481-9b1b-61e7d318c571",
   "metadata": {},
   "source": [
    "5c) Check the type of the variables \"year\" and \"iso3\" are string, if not convert them to string **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c1993423-8edf-4bb0-8ea0-69034fce5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before convert \n",
      "Year datatype: string\n",
      "iso3 datatype: string\n",
      "After convert \n",
      "Year datatype: string\n",
      "iso3 datatype: string\n"
     ]
    }
   ],
   "source": [
    "# Answer 5c\n",
    "print(f'Before convert \\nYear datatype: {df_qog[\"year\"].dtypes}')\n",
    "print(f'iso3 datatype: {df_qog[\"iso3\"].dtypes}')\n",
    "\n",
    "df_qog[['year', 'iso3']] = df_qog[['year', 'iso3']].astype('string')\n",
    "\n",
    "print(f'After convert \\nYear datatype: {df_qog[\"year\"].dtypes}')\n",
    "print(f'iso3 datatype: {df_qog[\"iso3\"].dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b61d4-55aa-439b-823f-67aad3f6fc16",
   "metadata": {},
   "source": [
    "### Question 6: Merge QOG and Polity5 ... issues with QOG? <a class=\"anchor\" id=\"question6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8af7f-3b38-4834-90b4-e1cbbb7b7359",
   "metadata": {},
   "source": [
    "6a) Get a subset of the dataframe that includes the variables \"cname\", \"iso3\", \"year\" and \"cckp_temp\", and display the number of rows. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8736cd36-ed4e-4dbd-96a9-c3d51bd343be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15225"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 6a\n",
    "\n",
    "df_qog_subset = df_qog[['cname', 'iso3',  'year', 'cckp_temp']]\n",
    "len(df_qog_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a0373-fab5-4346-bed7-3500ed9aced0",
   "metadata": {},
   "source": [
    "6b) Merge this subset (left) and the clean version of the polity data (right), using the argument how=\"left\". Was the merge succesfull? If yes, how many rows has the merged dataframe? Is it the same number of rows of the subset in 6a? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2bb2b0ba-fdd7-474a-9241-6d96e6eca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6b\n",
    "\n",
    "len(df_pol)\n",
    "merged = pd.merge(left=df_qog_subset, right=df_pol, how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e5a50-5bda-4331-82a9-9cfe09a365cb",
   "metadata": {},
   "source": [
    "6c) Do the same by adding the argument validate=\"one-to-one\". Can you make some hypotheses on why you get an error? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fee8e0a9-75e7-4c37-80ad-3f5ddef8d602",
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in either left or right dataset; not a one-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [176]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Answer 6c\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# By using the option validate='one-to-one', we get an error message which states that the merge keys are not unique. \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Which makes sense which we for example have several rows in the same column with the same value.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m merge_one_to_one \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_qog_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_pol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1:1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:710\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1427\u001b[0m, in \u001b[0;36m_MergeOperation._validate\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_to_one\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1:1\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_unique:\n\u001b[0;32m-> 1427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   1428\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in either left \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1429\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor right dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1430\u001b[0m         )\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left_unique:\n\u001b[1;32m   1432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   1433\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in left dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1434\u001b[0m         )\n",
      "\u001b[0;31mMergeError\u001b[0m: Merge keys are not unique in either left or right dataset; not a one-to-one merge"
     ]
    }
   ],
   "source": [
    "# Answer 6c\n",
    "\n",
    "# By using the option validate='one-to-one', we get an error message which states that the merge keys are not unique. \n",
    "# Which makes sense which we for example have several rows in the same column with the same value.\n",
    "merge_one_to_one = pd.merge(left=df_qog_subset, right=df_pol, validate='1:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8da9ac-de08-460e-b364-40aaf5a9aa34",
   "metadata": {},
   "source": [
    "6d) Consider the subset of the QOG you obtained in 6a and write a code to (i) count the number of observations for the variable \"cckp_temp\" for each combination of iso3 and year, (ii) store the results in a dataframe. For example, the combination \"USA-2012\" should have 1 observation for \"cckp_temp\", so the result of your code should be 1. The code should do this for all iso3-year combinations of your subset dataframe, and store the results in a dataframe. **(1 point)**\n",
    "<br>\n",
    "Hint: it should not take you more than 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "593a4be8-0760-454d-8f55-e5e0bd18af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6d\n",
    "cckp_temp_per_combination = df_qog_subset.groupby(['iso3', 'year'])['cckp_temp'].agg('count').reset_index()\n",
    "cckp_temp_per_combination.loc[cckp_temp_per_combination['cckp_temp'] > 1]\n",
    "\n",
    "#df_qog_subset[(df_qog_subset['iso3'] == 'VEN') & (df_qog_subset['year'] == '1956')]\n",
    "\n",
    "cckp_temp_per_combination.to_csv('cckp_temp_per_combination.csv')\n",
    "df_qog_subset.to_csv('df_qog_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e92628-2085-4edf-aed4-8e6db647d9c6",
   "metadata": {},
   "source": [
    "6e) Use the code in 6d to write a function that displays all rows of the dataframe obtained in 6a that have more than one observation of \"cckp_temp\" for each iso3-year combination, and check if it works. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e953896a-28a5-4d38-8ad3-93027c5c4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6e\n",
    "def more_than_one_cckp_temp(df):\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190da03-b34c-4566-8aec-5a1a540ac660",
   "metadata": {},
   "source": [
    "6f) Which countries have more than one observation for each iso3-year combination? Deal with these countries in the subset dataframe created in 6a to make sure you no longer have double observations for iso3-year combinations, and check that after your fix this is actually the case. **(1 point)**\n",
    "<br>\n",
    "Hint: should we keep a country with all missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6d960c4a-b755-448c-8952-aee2e6eee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae70541-6427-4f83-bd05-37ef68baf5cd",
   "metadata": {},
   "source": [
    "6g) If your check went well, now you can perform the same operation directly in the QOG dataframe (not in the substed dataframe created in 6a). How many rows does now the QOG dataframe has? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c9f20b2-04e4-46d0-94f6-e580913ddfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd12e1-799e-4e4c-8d13-db496fb5bab4",
   "metadata": {},
   "source": [
    "### Question 7: Merge QOG and Polity5 ... issues with Polity5? <a class=\"anchor\" id=\"question7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72692a86-a9ab-44bb-bb56-b3c22e0829c4",
   "metadata": {},
   "source": [
    "7a) Merge the cleaned QOG dataframe (left) and the Polity dataframe (right) using the options how=\"left\" and validate=\"one_to_one\". Does it work? Why? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82261ca5-c3ec-49f6-8de8-be1b14943cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95740ccf-88d7-46ee-82ab-f1a8b42d9722",
   "metadata": {},
   "source": [
    "7b) Use the function you wrote in 6e to check what's wrong in the \"clean\" version of Polity **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "356409a0-73e8-41ac-af75-c2f6a462c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d8f5b-10f5-4540-b714-99b77f3e5203",
   "metadata": {},
   "source": [
    "7c) Drop or fix the countries that create troubles directly in the \"clean\" version of Polity and motivate your choices. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8aeb945c-418a-4eee-bdd3-2dce12246196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88282d66-3aa1-4fa4-b7cc-b448c649052c",
   "metadata": {},
   "source": [
    "7d) Try now to merge the \"clean-clean\" versions of qog and Polity (the ones you obtained in 7g and 8c) always using the options how=\"left\" and validate=\"one_to_one\". Does it work, and why? How many rows has the resulting merged dataframe? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12e52b0f-7484-4656-82bd-8de4cee284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8479c-556a-4c9b-b89f-a8f714e888ad",
   "metadata": {},
   "source": [
    "### Question 8: Clean the merged dataframe <a class=\"anchor\" id=\"question8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936854f-7882-47bc-a2c0-cb39b53128b0",
   "metadata": {},
   "source": [
    "8a) In the merged dataframe, order the columns so that you have the \"index\" variables first and the variables with actual values last. **(1 point)**\n",
    "<br>\n",
    "Hint: index variables are \"iso3\", \"year\" and other similar variables you can find, and the variables with actual values are \"polity2\", \"cckp_temp\" and other similar variables you can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7e92ad2-8007-4a4b-a47f-44c040ccfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39c4e8-6f99-47c9-9d32-4196e4184537",
   "metadata": {},
   "source": [
    "8b) Rename \"cname\" as \"country\" and \"country\" as \"country_polity\". **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89e2cccd-473d-462e-9b2f-726aa6763d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353db63e-08d7-41df-9bdf-e0aa20174569",
   "metadata": {},
   "source": [
    "8c) Save the clean merged dataframe as a csv in a subfolder called \"clean_data\" in your working directory **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8a684c82-6df7-480f-9374-a2d4e7ec069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2840-c690-4b3e-8e4c-0025101bdc62",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa01e2b-dc8a-49ae-a19b-8c42bd0f2e57",
   "metadata": {},
   "source": [
    "In this section you will define a research question and perform a preliminary Exploratory Data Analysis (EDA) to address - or better, start addressing - the question at hand. This exercise will be done along the lines of the analysis done by our own Quentin Gallea in \"*A recipe to empirically answer any question quickly*\" ([Towards Data Science, 2022](https://towardsdatascience.com/a-recipe-to-empirically-answer-any-question-quickly-22e48c867dd5)). In this article, Quentin shows the first steps of an EDA that aims to explore whether heat waves have pushed governments to implement regulations against climate change (causal link). The logic is that, as it gets hotter and hotter, governments become more aware of climate change, and the problems it can cause to society, and start addressing it. In Quentin's analysis, heat waves (proxied by temperature) is the \"main explanatory variable\", rainfall is the \"explanatory variable for heterogeneity\", and regulations against climate change (proxied by the Environmental Policy Stringency Index) is the \"outcome variable\". He finds that indeed countries with relatively high temperatures have implemented more regulations against climate change. This is true especially when rainfall levels are low, as when it does not rain the damage of extreme heat is more evident to legislators, who therefore apply stricter regulations against these phenomenons.\n",
    "<br>\n",
    "<br>\n",
    "In this exercise, you will be asked to do a similar analysis on a research question of your choice, using at least two of the variables of the dataset we have created in the former questions (QOG + Polity). For example, \"what is the average temperature in 2010?\" is not a valid research question (univariate), while \"what is the impact of high temperatures on the stringency of climate regulations?\" is a valid research question (at least bivariate). As before, we will ask you some (this time more general and open) questions, and you should report your answer in the cells below each question. Use a mix of markdown and code cells to answer (markdown for text and code for graphs and tables). We should be able to run all the graphs, i.e. screenshots of graphs are not accepted. Note that for now we have put only one markdown cell and one code cell for the answer, but feel free to add as many cells as you need.\n",
    "<br>\n",
    "Beyond the python code, we will grade the interpretations of the results and the coding decision you make.\n",
    "<br>\n",
    "<br>\n",
    "Let your creativity guide you and let's have some fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97f39-3b6d-4546-8871-b136d122854c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 9: Selecting the ingredients (how I select the variables) <a class=\"anchor\" id=\"question9\"></a>\n",
    "We have saved the clean merged data that resulted from the previous questions in \"clean_data_prepared_EDA\" (it should be the same of the one you saved in \"clean_data\"). Import the clean merged data from \"clean_data_prepared_EDA\" using this [link](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/clean_data_prepared_EDA/df_qog_polity_merged.csv). Explore the variables in the newly obtained dataframe by checking the documentation of QOG and Polity. Then, define a research question that addresses a causal link between at least two of these variables. Describe the research question, why you are addressing it and the variables of interest (outcome variable, main explanatory variable and explanatory variable for heterogeneity). **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df577a5-f0f1-43e8-aeb1-0708fe53892b",
   "metadata": {},
   "source": [
    "Answer 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b575ca1f-de5a-4b03-a51a-7f0cc5fa18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b5531-0329-4817-a341-d1a1bb96ef2d",
   "metadata": {},
   "source": [
    "### Question 10: Picking the right quantity of each ingredient (how I select my sample) <a class=\"anchor\" id=\"question10\"></a>\n",
    "Explore the data availability of your variables of interest and select a clean sample for the analysis. Describe this sample with the help of summary-statistics tables and maps. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef40ba-ff3a-4983-99c7-151be2f9622e",
   "metadata": {},
   "source": [
    "Answer 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb262470-32d1-4d2c-af1c-8616daed69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4434c1-4ca5-44af-a24c-67a1b8d20cc6",
   "metadata": {},
   "source": [
    "### Question 11: Tasting and preparing the ingredients (univariate analysis) <a class=\"anchor\" id=\"question11\"></a>\n",
    "Do an univariate analysis for each variable you have chosen (outcome variable, main explanatory variable and explanatory variable for heterogeneity):\n",
    "- Prepare the variable, for example see if you need to transform the data further, i.e. log-transform, define a categorical variable, deal with outliers, etc.\n",
    "- Understand the nature of the variable, i.e. continuous, categorical, binary, etc., which then allows to pick the right statistical tool in the bivariate analysis.\n",
    "- Get an idea of the variable's behaviour across time and space.\n",
    "\n",
    "Describe these steps and the conclusions you can draw with the help of histograms, tables, maps and line graphs. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef687c9b-69c5-49b0-adb3-2aac7406112c",
   "metadata": {},
   "source": [
    "Answer 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3fffac2-d33c-410f-9f10-c190a4c59641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ad4a-70fc-4f39-bffb-cf10dd93205f",
   "metadata": {},
   "source": [
    "### Question 12: Cooking the ingredients together (bivariate analysis) <a class=\"anchor\" id=\"question12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c658-8c22-4bb0-b1ef-4b5860f6cc31",
   "metadata": {},
   "source": [
    "Considering the \"nature\" of your variables (continuous, categorical, binary, etc.), pick the right tool / tools for a preliminary bivariate analysis, i.e. correlation tables, bar/line graphs, scatter plots, etc. Use these tools to describe your preliminary bivariate analysis and your findings. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bb04c-9223-4e3d-b815-2d7ee3657f00",
   "metadata": {},
   "source": [
    "Answer 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a6c0962-c661-4649-b8f3-e721e7ef66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 12:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0a05d-004a-42f3-b472-b7a808cd0dc1",
   "metadata": {},
   "source": [
    "### Question 13: Tasting the new recipe (conclusion) <a class=\"anchor\" id=\"question13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b861d-d4d5-42b1-94ad-5aa33f9bf7a2",
   "metadata": {},
   "source": [
    "Explain what you learned, the problem faced, what would you do next (you can suggest other data you would like to have etc). **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536aef2-a8df-4e17-9089-01ba8d93c029",
   "metadata": {},
   "source": [
    "Answer 13:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
