{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795860f2-eabf-40d1-954c-843dcf672a7d",
   "metadata": {},
   "source": [
    "# MGT-499 Statistics and Data Science - Individual Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a58faf4-db28-41c1-9e6d-ead96d328eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here what you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5761d-3238-4e69-951f-6fea4557ef41",
   "metadata": {},
   "source": [
    "This notebook contains the individual assignment for the class MGT-499 Statistics and Data Science. Important information:\n",
    "- **Content**: the assignment is divided in two main parts, namely data cleaning (2 datasets) and Exploratory Data Analysis, for a total of 13 main questions (see table of contents). Some of these main questions are divided in sub questions. In the first part, the questions are very specific, while in the second part they are more open.\n",
    "- **Deadline**: Tuesday 8th of November at 23:59. \n",
    "- **Final Output**: a Jupyter notebook, which we (teachers) can run. \n",
    "- **Answering the Questions**: you will find the questions in markdown cells below. Under each of these cells, you will find a cell / cells for answers. Type there your answer. For the answer to be correct, the cell with the answer must run without error (unless specified). You can use markdown cells for the answers that require text.\n",
    "- **Submission**: submit the assignment on Moodle, under [Individual Assignment](https://moodle.epfl.ch/mod/assign/view.php?id=1222846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43ccf-9ed6-44ea-8dd3-184cb9e7c499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Content\n",
    "- [Polity5 Dataset](#polity5)  \n",
    "    - [Question 1: Import the data and get a first glance](#question1)\n",
    "    - [Question 2: Select some variables](#question2)\n",
    "    - [Question 3: Missing Values](#question3)\n",
    "    - [Question 4: Check Polity2](#question4)\n",
    "- [Quality of Government (QOG) Environmental Indicators Dataset](#qog)  \n",
    "    - [Question 5: Import the data and do few fixes](#question5)\n",
    "    - [Question 6: Merge QOG and Polity5 ... first attempt](#question6)\n",
    "    - [Question 7: Merge QOG and Polity5 ... second attempt](#question7)\n",
    "    - [Question 8: Clean the merged dataframe](#question8)\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "    - [Question 9: Selecting the ingredients for the recipe (how I select the variables)](#question9)  \n",
    "    - [Question 10: Picking the right quantity of each ingredient (how I select my sample)](#question10)\n",
    "    - [Question 11: Tasting and preparing the ingredients (univariate analysis)](#question11)\n",
    "    - [Question 12: Cooking the ingredients together (bivariate analysis)](#question12)\n",
    "    - [Question 13: Tasting the new recipe (conclusion)](#question13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142f738-6239-4e12-9c65-fd27b4db73ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polity5 data <a class=\"anchor\" id=\"polity5\"></a>\n",
    "\n",
    "Polity5 is a widely used democracy scale. The raw data as well as the codebook are available [here](http://www.systemicpeace.org/inscrdata.html). For this assignment, we have modified a bit the original version, for example we have added the iso3 code for countries to make you save time. You can find the modified version [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903da7f-480e-4777-a4ef-9ab94b09e473",
   "metadata": {},
   "source": [
    "### Question 1: import the data and get a first glance <a class=\"anchor\" id=\"question1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f6829-6c8f-451a-9670-4d1c7a103c12",
   "metadata": {},
   "source": [
    "1a) Import the csv 'polity2_iso3.csv' (file provided in the link [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)) as a panda dataframe (ignore the warning message) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee7e4014-e55c-4994-a633-61a8fdf1e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1a\n",
    "url = 'https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv'\n",
    "polity_data = pd.read_csv(url, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd738c61-10ca-4439-8bcf-20e6987e3e5f",
   "metadata": {},
   "source": [
    "1b) Display the first 10 rows **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "10544e0c-33b5-4b90-ad68-4cfe8d6c40b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3</th>\n",
       "      <th>year</th>\n",
       "      <th>p5</th>\n",
       "      <th>cyear</th>\n",
       "      <th>ccode</th>\n",
       "      <th>scode</th>\n",
       "      <th>country</th>\n",
       "      <th>flag</th>\n",
       "      <th>fragment</th>\n",
       "      <th>democ</th>\n",
       "      <th>...</th>\n",
       "      <th>interim</th>\n",
       "      <th>bmonth</th>\n",
       "      <th>bday</th>\n",
       "      <th>byear</th>\n",
       "      <th>bprec</th>\n",
       "      <th>post</th>\n",
       "      <th>change</th>\n",
       "      <th>d5</th>\n",
       "      <th>sf</th>\n",
       "      <th>regtrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>2711800</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>7301800</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>2451800</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "      <td>-10</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>7301801</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>2711801</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>2451801</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>7301802</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>2711802</td>\n",
       "      <td>271</td>\n",
       "      <td>WRT</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "      <td>2451802</td>\n",
       "      <td>245</td>\n",
       "      <td>BAV</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1803</td>\n",
       "      <td>0</td>\n",
       "      <td>7301803</td>\n",
       "      <td>730</td>\n",
       "      <td>KOR</td>\n",
       "      <td>Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso3  year  p5    cyear  ccode scode       country  flag  fragment  democ  \\\n",
       "0  NaN  1800   0  2711800    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "1  NaN  1800   0  7301800    730   KOR         Korea     0       NaN      5   \n",
       "2  NaN  1800   0  2451800    245   BAV       Bavaria     0       NaN      0   \n",
       "3  NaN  1801   0  7301801    730   KOR         Korea     0       NaN      5   \n",
       "4  NaN  1801   0  2711801    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "5  NaN  1801   0  2451801    245   BAV       Bavaria     0       NaN      0   \n",
       "6  NaN  1802   0  7301802    730   KOR         Korea     0       NaN      5   \n",
       "7  NaN  1802   0  2711802    271   WRT  Wuerttemburg     0       NaN      0   \n",
       "8  NaN  1802   0  2451802    245   BAV       Bavaria     0       NaN      0   \n",
       "9  NaN  1803   0  7301803    730   KOR         Korea     0       NaN      5   \n",
       "\n",
       "   ...  interim  bmonth  bday byear  bprec  post  change   d5   sf  regtrans  \n",
       "0  ...      NaN       1     1  1800      1    -7      88    1  NaN       NaN  \n",
       "1  ...      NaN       1     1  1800      1     1      88    1  NaN       NaN  \n",
       "2  ...      NaN       1     1  1800      1   -10      88    1  NaN       NaN  \n",
       "3  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "4  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "5  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "6  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "7  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "8  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "9  ...      NaN     NaN   NaN   NaN    NaN   NaN     NaN  NaN  NaN       NaN  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 1b\n",
    "polity_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6decfca-afb8-4c77-881c-8fb78d96e68d",
   "metadata": {},
   "source": [
    "1c) Display the data types of all the variables included in the data **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aa768541-03f9-424a-a690-d6132298f36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iso3</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p5</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyear</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccode</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scode</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragment</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>democ</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autoc</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polity</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polity2</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>durable</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xrreg</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xrcomp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xropen</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xconst</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parreg</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcomp</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exrec</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exconst</th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polcomp</th>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emonth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eday</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eyear</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eprec</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interim</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmonth</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bday</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byear</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bprec</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regtrans</th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "iso3       object\n",
       "year        int64\n",
       "p5          int64\n",
       "cyear       int64\n",
       "ccode       int64\n",
       "scode      object\n",
       "country    object\n",
       "flag        int64\n",
       "fragment  float64\n",
       "democ       int64\n",
       "autoc       int64\n",
       "polity      int64\n",
       "polity2   float64\n",
       "durable    object\n",
       "xrreg       int64\n",
       "xrcomp      int64\n",
       "xropen      int64\n",
       "xconst      int64\n",
       "parreg      int64\n",
       "parcomp     int64\n",
       "exrec     float64\n",
       "exconst     int64\n",
       "polcomp   float64\n",
       "prior      object\n",
       "emonth     object\n",
       "eday       object\n",
       "eyear      object\n",
       "eprec      object\n",
       "interim    object\n",
       "bmonth     object\n",
       "bday       object\n",
       "byear      object\n",
       "bprec      object\n",
       "post       object\n",
       "change     object\n",
       "d5         object\n",
       "sf         object\n",
       "regtrans   object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 1c\n",
    "data_type  = polity_data.dtypes\n",
    "data_type.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ee31a-7cc9-44d2-b7f8-242f6ee5ebfc",
   "metadata": {},
   "source": [
    "1d) By looking at your answer in 1c, what is the difference between the different types of variables? Why the type of some variables is defined as object? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97f628-71b6-4aac-9c9c-596773557131",
   "metadata": {},
   "source": [
    "Answer 1d:\n",
    "\n",
    "We can see that we have four different dataypes: `object`, `float64` and `int64`. `Object` is  the pandas type for mixed values s.a. strings and numbers. In python the equivivalent  type is `string`. `Float64` refers to numeric characters with decimals. If columns contain numbers and NaN pandas will defualt to `float64`. And for `int64` is for integer numbers, and the 64 refers to memory allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfba84f-b897-4fcb-880d-9d8995045239",
   "metadata": {},
   "source": [
    "### Question 2. Select some variables <a class=\"anchor\" id=\"question2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9776a-26ed-4154-af73-0e2b337e9e74",
   "metadata": {},
   "source": [
    "2a) Create a subset dataframe that contains the variables 'iso3', 'country', 'year', 'polity2' and display it **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b3bd0a39-386d-4397-93eb-8eb7e0415a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>polity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>1800</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Korea</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>1800</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Korea</td>\n",
       "      <td>1801</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>1801</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17570</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17572</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17574 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso3       country  year  polity2\n",
       "0      NaN  Wuerttemburg  1800     -7.0\n",
       "1      NaN         Korea  1800      1.0\n",
       "2      NaN       Bavaria  1800    -10.0\n",
       "3      NaN         Korea  1801      1.0\n",
       "4      NaN  Wuerttemburg  1801     -7.0\n",
       "...    ...           ...   ...      ...\n",
       "17569  ZWE      Zimbabwe  2014      4.0\n",
       "17570  ZWE      Zimbabwe  2015      4.0\n",
       "17571  ZWE      Zimbabwe  2016      4.0\n",
       "17572  ZWE      Zimbabwe  2017      4.0\n",
       "17573  ZWE      Zimbabwe  2018      4.0\n",
       "\n",
       "[17574 rows x 4 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2a\n",
    "polity_data_subset = (polity_data[['iso3', 'country', 'year', 'polity2']]).copy()\n",
    "polity_data_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4883d-8f9e-4b1f-9ce4-c62267090287",
   "metadata": {},
   "source": [
    "2b) Display the type of the variable \"year\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0dc6b73-70d9-42c0-9cd1-716033325a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2b\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639b2d3-b5e6-40f3-93c9-6547bcdcb814",
   "metadata": {},
   "source": [
    "2c) Convert the variable \"year\" to string **(1 point)**\n",
    "<br>\n",
    "Hint: if you get a warning message of the type \"SettingWithCopyWarning\", it is because you did not subset the data in the right way. Go back to your class notes and check the different ways to subset a dataframe, and try again. If you do it correctly, you will not get the warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "914d8f60-9875-40be-9f78-0c7c2837a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "string[python]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2c\n",
    "polity_data_subset['year'] = polity_data_subset['year'].astype('string')\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0babf3-0e33-4e13-9289-523ecef5e004",
   "metadata": {},
   "source": [
    "### Question 3: Missing Values <a class=\"anchor\" id=\"question3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb19a0f-bd7c-4d9c-bdfa-05e55e4eb26f",
   "metadata": {},
   "source": [
    "3a) Subset the rows that have iso3 missing and display **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7eb48bb3-a92a-4565-8a5c-f22f642f2661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>polity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>1800</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Korea</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bavaria</td>\n",
       "      <td>1800</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Korea</td>\n",
       "      <td>1801</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Wuerttemburg</td>\n",
       "      <td>1801</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2018</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2018</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso3       country  year  polity2\n",
       "0     NaN  Wuerttemburg  1800     -7.0\n",
       "1     NaN         Korea  1800      1.0\n",
       "2     NaN       Bavaria  1800    -10.0\n",
       "3     NaN         Korea  1801      1.0\n",
       "4     NaN  Wuerttemburg  1801     -7.0\n",
       "...   ...           ...   ...      ...\n",
       "1272  NaN    Montenegro  2018      9.0\n",
       "1273  NaN   Sudan-North  2018     -4.0\n",
       "1274  NaN       Vietnam  2018     -7.0\n",
       "1275  NaN      Ethiopia  2018      1.0\n",
       "1276  NaN        Serbia  2018      8.0\n",
       "\n",
       "[1270 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3a\n",
    "iso_missing = polity_data_subset[polity_data_subset['iso3'].isna()]\n",
    "iso_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b352b-c860-4b2c-bca3-5437c2bbaf23",
   "metadata": {},
   "source": [
    "3b) Display the countries that have missing iso3. What can you tell by looking at them? Any similarities? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b7e9760a-a4a6-4826-b377-49ff300662f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They seem to be old countries, or old country names.\n",
      "['Wuerttemburg' 'Korea' 'Bavaria' 'Saxony' 'Parma' 'Tuscany' 'Sardinia'\n",
      " 'Modena' 'Two Sicilies' 'Baden' 'Gran Colombia' 'United Province CA'\n",
      " 'Serbia' 'Orange Free State' 'Yemen North' 'Czechoslovakia' 'USSR'\n",
      " 'Germany West' 'Germany East' 'Pakistan' 'South Vietnam' 'Yemen South'\n",
      " 'Vietnam' 'Yugoslavia' 'Ethiopia' 'Serbia and Montenegro' 'Montenegro'\n",
      " 'Sudan-North']\n"
     ]
    }
   ],
   "source": [
    "# Answer 3b\n",
    "iso_missing_contries = iso_missing['country']\n",
    "print(f'They seem to be old countries, or old country names.\\n{iso_missing_contries.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41b9a2-2c70-41c6-b891-95e01f2a74a5",
   "metadata": {},
   "source": [
    "3c) Display the countries with missing iso3 from 2011. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b408fff2-6493-4dff-9294-ef1c564315fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethiopia', 'Montenegro', 'Serbia', 'Sudan-North', 'Vietnam']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3c\n",
    "# Interpreting the question so that we take the contries missing iso3 from 2011 onwards\n",
    "global df_missing_iso3_since_2011\n",
    "global df_missing_iso3_since_2011_list\n",
    "\n",
    "df_missing_iso3_since_2011 = iso_missing[iso_missing['year'] >= '2011']\n",
    "df_missing_iso3_since_2011_list = sorted(df_missing_iso3_since_2011['country'].unique())\n",
    "df_missing_iso3_since_2011_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9a6b6-2151-4c5e-8a8a-ea9810905642",
   "metadata": {},
   "source": [
    "3d) Display the rows for which the column \"country\" contains the word \"Serbia\". By looking at the result, can you tell what happened to Serbia in 2006? **(1 point)**\n",
    "<br>\n",
    "Hint: the most general way of doing this is to use a combination of re.search and list comprehension. To display the full subset, you can use print(df.to_string())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a953ca64-d67b-4c94-8df6-5077efa68814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     iso3                country  year  polity2\n",
      "224   NaN                 Serbia  1830     -7.0\n",
      "230   NaN                 Serbia  1831     -7.0\n",
      "252   NaN                 Serbia  1832     -7.0\n",
      "261   NaN                 Serbia  1833     -7.0\n",
      "272   NaN                 Serbia  1834     -7.0\n",
      "286   NaN                 Serbia  1835     -7.0\n",
      "295   NaN                 Serbia  1836     -7.0\n",
      "301   NaN                 Serbia  1837     -7.0\n",
      "318   NaN                 Serbia  1838      2.0\n",
      "333   NaN                 Serbia  1839      2.0\n",
      "344   NaN                 Serbia  1840      2.0\n",
      "357   NaN                 Serbia  1841      2.0\n",
      "363   NaN                 Serbia  1842      2.0\n",
      "369   NaN                 Serbia  1843      2.0\n",
      "387   NaN                 Serbia  1844      2.0\n",
      "394   NaN                 Serbia  1845      2.0\n",
      "410   NaN                 Serbia  1846      2.0\n",
      "420   NaN                 Serbia  1847      2.0\n",
      "429   NaN                 Serbia  1848      2.0\n",
      "439   NaN                 Serbia  1849      2.0\n",
      "450   NaN                 Serbia  1850      2.0\n",
      "467   NaN                 Serbia  1851      2.0\n",
      "475   NaN                 Serbia  1852      2.0\n",
      "482   NaN                 Serbia  1853      2.0\n",
      "492   NaN                 Serbia  1854      2.0\n",
      "502   NaN                 Serbia  1855      2.0\n",
      "523   NaN                 Serbia  1856      2.0\n",
      "533   NaN                 Serbia  1857      2.0\n",
      "542   NaN                 Serbia  1858     -9.0\n",
      "553   NaN                 Serbia  1859     -9.0\n",
      "572   NaN                 Serbia  1860     -4.0\n",
      "575   NaN                 Serbia  1861      0.0\n",
      "583   NaN                 Serbia  1862      0.0\n",
      "593   NaN                 Serbia  1863      0.0\n",
      "601   NaN                 Serbia  1864      0.0\n",
      "608   NaN                 Serbia  1865      0.0\n",
      "611   NaN                 Serbia  1866      0.0\n",
      "623   NaN                 Serbia  1867      0.0\n",
      "628   NaN                 Serbia  1868     -3.0\n",
      "637   NaN                 Serbia  1869     -5.0\n",
      "642   NaN                 Serbia  1870     -5.0\n",
      "651   NaN                 Serbia  1871     -5.0\n",
      "652   NaN                 Serbia  1872     -5.0\n",
      "657   NaN                 Serbia  1873     -5.0\n",
      "660   NaN                 Serbia  1874     -5.0\n",
      "663   NaN                 Serbia  1875     -5.0\n",
      "665   NaN                 Serbia  1876     -5.0\n",
      "669   NaN                 Serbia  1877     -5.0\n",
      "671   NaN                 Serbia  1878     -5.0\n",
      "673   NaN                 Serbia  1879     -5.0\n",
      "676   NaN                 Serbia  1880     -5.0\n",
      "680   NaN                 Serbia  1881     -5.0\n",
      "684   NaN                 Serbia  1882     -5.0\n",
      "686   NaN                 Serbia  1883     -5.0\n",
      "690   NaN                 Serbia  1884     -5.0\n",
      "693   NaN                 Serbia  1885     -5.0\n",
      "694   NaN                 Serbia  1886     -5.0\n",
      "697   NaN                 Serbia  1887     -5.0\n",
      "700   NaN                 Serbia  1888     -5.0\n",
      "704   NaN                 Serbia  1889     -5.0\n",
      "708   NaN                 Serbia  1890     -5.0\n",
      "709   NaN                 Serbia  1891     -5.0\n",
      "714   NaN                 Serbia  1892     -5.0\n",
      "715   NaN                 Serbia  1893     -5.0\n",
      "718   NaN                 Serbia  1894     -5.0\n",
      "722   NaN                 Serbia  1895     -5.0\n",
      "724   NaN                 Serbia  1896     -5.0\n",
      "729   NaN                 Serbia  1897     -5.0\n",
      "730   NaN                 Serbia  1898     -5.0\n",
      "733   NaN                 Serbia  1899     -5.0\n",
      "737   NaN                 Serbia  1900     -5.0\n",
      "739   NaN                 Serbia  1901     -5.0\n",
      "743   NaN                 Serbia  1902     -5.0\n",
      "745   NaN                 Serbia  1903      4.0\n",
      "748   NaN                 Serbia  1904      4.0\n",
      "749   NaN                 Serbia  1905      4.0\n",
      "751   NaN                 Serbia  1906      4.0\n",
      "753   NaN                 Serbia  1907      4.0\n",
      "755   NaN                 Serbia  1908      4.0\n",
      "758   NaN                 Serbia  1909      4.0\n",
      "759   NaN                 Serbia  1910      4.0\n",
      "761   NaN                 Serbia  1911      4.0\n",
      "762   NaN                 Serbia  1912      4.0\n",
      "763   NaN                 Serbia  1913      4.0\n",
      "764   NaN                 Serbia  1914      4.0\n",
      "765   NaN                 Serbia  1915      NaN\n",
      "766   NaN                 Serbia  1916      NaN\n",
      "767   NaN                 Serbia  1917      4.0\n",
      "769   NaN                 Serbia  1918      5.0\n",
      "773   NaN                 Serbia  1919      6.0\n",
      "774   NaN                 Serbia  1920      7.0\n",
      "1201  NaN  Serbia and Montenegro  2003      6.0\n",
      "1205  NaN  Serbia and Montenegro  2004      6.0\n",
      "1207  NaN  Serbia and Montenegro  2005      6.0\n",
      "1212  NaN  Serbia and Montenegro  2006      6.0\n",
      "1213  NaN                 Serbia  2006      8.0\n",
      "1217  NaN                 Serbia  2007      8.0\n",
      "1218  NaN                 Serbia  2008      8.0\n",
      "1224  NaN                 Serbia  2009      8.0\n",
      "1228  NaN                 Serbia  2010      8.0\n",
      "1231  NaN                 Serbia  2011      8.0\n",
      "1238  NaN                 Serbia  2012      8.0\n",
      "1247  NaN                 Serbia  2013      8.0\n",
      "1248  NaN                 Serbia  2014      8.0\n",
      "1254  NaN                 Serbia  2015      8.0\n",
      "1263  NaN                 Serbia  2016      8.0\n",
      "1269  NaN                 Serbia  2017      8.0\n",
      "1276  NaN                 Serbia  2018      8.0\n"
     ]
    }
   ],
   "source": [
    "# Answer 3d\n",
    "\n",
    "# It is important to check for varieties of capilized firstletter when using case sensitive comparison. Information may be lost. Here all country instances uses first capital letter.\n",
    "polity_data_subset_serbia = polity_data_subset[polity_data_subset['country'].str.contains(pat='Serbia')]\n",
    "print(polity_data_subset_serbia.to_string())\n",
    "\n",
    "# We can see that the country referred to as Serbia, reappeared in 2006, this is due to a name change following Montenegro and Serbias decleration of independence of their previous union named `Serbia and Montenegro`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd97b-0aaa-4bca-affb-22f3c0ca387c",
   "metadata": {},
   "source": [
    "3e) Write a function that does the operation in 3d and use it to display the subset that has the word \"sudan\" (all lower cap) in country. Then do the same for the word \"vietnam\" (all lower cap). **(1 point)**\n",
    "<br>\n",
    "Hint: options of functions can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3217b330-72ef-4d38-8a66-1849d12f7dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [iso3, country, year, polity2]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [iso3, country, year, polity2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Answer 3e\n",
    "#\n",
    "# Function find_country\n",
    "# \tinput: datafram, string\n",
    "# \toutput: df containting the specified string in the column 'country'\n",
    "\n",
    "def find_country(df:pd.DataFrame, country:str):\n",
    "\ttry:\n",
    "\t\treturn df[df['country'].str.contains(pat=country)]\n",
    "\texcept TypeError as e:\n",
    "\t\tprint(f'Not a valid datatype: {e}.\\nUse {pd.DataFrame} and {str} as option type parameters')\n",
    "\n",
    "df_sudan = find_country(polity_data_subset, 'sudan')\n",
    "df_vietnam = find_country(polity_data_subset, 'vietnam')\n",
    "\n",
    "print(df_sudan)\n",
    "print(df_vietnam)\n",
    "\n",
    "# str.contains is by default case sensitive, so we can just feed the function with 'sudan' or 'vietnam'\n",
    "# Both empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a0adc-6104-4dff-baa4-cbc8259183b4",
   "metadata": {},
   "source": [
    "3f) Replace nan values in iso3 with correct iso3 for the 5 countries found in 3c from 2011 onwards, and display the subset with the fixed values to check that everything worked. **(1 point)**\n",
    "<br>\n",
    "Hint: the correct iso3 for these 5 countries are \"ETH\",\"MNE\",\"SRB\",\"SDN\",\"VNM\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72ab9532-5a03-46fe-9db7-170e8b087957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso3</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>polity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2011</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2011</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2011</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2011</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2012</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2012</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2012</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2013</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2013</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2013</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2013</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2014</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2014</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2014</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2014</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2015</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2015</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2015</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2015</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2015</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2016</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2016</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2016</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2016</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2017</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2017</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2017</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2017</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2017</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>MNE</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>SDN</td>\n",
       "      <td>Sudan-North</td>\n",
       "      <td>2018</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2018</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso3      country  year  polity2\n",
       "1230  MNE   Montenegro  2011      9.0\n",
       "1231  SRB       Serbia  2011      8.0\n",
       "1233  ETH     Ethiopia  2011     -3.0\n",
       "1234  SDN  Sudan-North  2011     -4.0\n",
       "1235  VNM      Vietnam  2011     -7.0\n",
       "1236  MNE   Montenegro  2012      9.0\n",
       "1238  SRB       Serbia  2012      8.0\n",
       "1239  ETH     Ethiopia  2012     -3.0\n",
       "1240  VNM      Vietnam  2012     -7.0\n",
       "1241  SDN  Sudan-North  2012     -4.0\n",
       "1242  VNM      Vietnam  2013     -7.0\n",
       "1243  MNE   Montenegro  2013      9.0\n",
       "1244  SDN  Sudan-North  2013     -4.0\n",
       "1245  ETH     Ethiopia  2013     -3.0\n",
       "1247  SRB       Serbia  2013      8.0\n",
       "1248  SRB       Serbia  2014      8.0\n",
       "1249  ETH     Ethiopia  2014     -3.0\n",
       "1251  MNE   Montenegro  2014      9.0\n",
       "1252  SDN  Sudan-North  2014     -4.0\n",
       "1253  VNM      Vietnam  2014     -7.0\n",
       "1254  SRB       Serbia  2015      8.0\n",
       "1255  ETH     Ethiopia  2015     -3.0\n",
       "1256  SDN  Sudan-North  2015     -4.0\n",
       "1258  VNM      Vietnam  2015     -7.0\n",
       "1259  MNE   Montenegro  2015      9.0\n",
       "1260  MNE   Montenegro  2016      9.0\n",
       "1262  SDN  Sudan-North  2016     -4.0\n",
       "1263  SRB       Serbia  2016      8.0\n",
       "1264  VNM      Vietnam  2016     -7.0\n",
       "1265  ETH     Ethiopia  2016     -3.0\n",
       "1266  VNM      Vietnam  2017     -7.0\n",
       "1268  ETH     Ethiopia  2017     -3.0\n",
       "1269  SRB       Serbia  2017      8.0\n",
       "1270  SDN  Sudan-North  2017     -4.0\n",
       "1271  MNE   Montenegro  2017      9.0\n",
       "1272  MNE   Montenegro  2018      9.0\n",
       "1273  SDN  Sudan-North  2018     -4.0\n",
       "1274  VNM      Vietnam  2018     -7.0\n",
       "1275  ETH     Ethiopia  2018      1.0\n",
       "1276  SRB       Serbia  2018      8.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 3f\n",
    "\n",
    "# Storing the correct iso3 values in a list\n",
    "iso3_code_missing = ('ETH', 'MNE', 'SRB', 'SDN', 'VNM')\n",
    "\n",
    "# Creating a dict to look up correct iso3 values with list from 3c\n",
    "iso3_dict = dict(zip(df_missing_iso3_since_2011_list, iso3_code_missing))\n",
    "\n",
    "# Copying the politydata to work on\n",
    "polity_data_subset_iso_replace = polity_data_subset.copy()\n",
    "\n",
    "# Function: replace(df, dct, replaced)\n",
    "# input: df: dataframe, dct: dictionary to loop through, replaced: item to be replaced\n",
    "# manipulates in place\n",
    "\n",
    "def replace(df, dct, replaced):\n",
    "    for key, item in dct.items():\n",
    "        df.loc[(df['country'] == key) & (df['year'].astype(int) >= 2011)] = df.loc[(\n",
    "            df['country'] == key) & (df['year'].astype(int) >= 2011)].replace(replaced, item)\n",
    "\n",
    "\n",
    "# Calling the function and telling which value i want to replace\n",
    "replace(polity_data_subset_iso_replace, iso3_dict, np.nan)\n",
    "\n",
    "# Using the indexes of the subset created in 3c to check if we have the correct countrycodes\n",
    "polity_data_subset_iso_replace.iloc[df_missing_iso3_since_2011.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa210c-b46f-46ff-a8da-d72d95bff196",
   "metadata": {},
   "source": [
    "3g) Drop the remaining rows which have nan in \"iso3\" and display the new number of rows of the dataframe (how many are they?) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c2cea78-0af1-405f-aeed-41dfc8fee4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing rows with NaNs in column \"iso3\" we had: 17574 rows\n",
      "Now we have: 16344 rows\n",
      "Which means that we removed: 1230 rows\n",
      "Which makes sense since we had 1230 instances of NaNs in the polity2 column.\n"
     ]
    }
   ],
   "source": [
    "# Answer 3g\n",
    "\n",
    "# Parameter axis=0 deletes the whole row, and the subset=iso3 means that we only look for NaNs in column iso3\n",
    "polity_data_ss_cleaner = polity_data_subset_iso_replace.dropna(subset='iso3', axis=0)\n",
    "\n",
    "# Number of rows\n",
    "print(f'Before removing rows with NaNs in column \"iso3\" we had: {len(polity_data_subset_iso_replace)} rows')\n",
    "print(f'Now we have: {len(polity_data_ss_cleaner)} rows')\n",
    "print(f'Which means that we removed: {len(polity_data_subset_iso_replace) - len(polity_data_ss_cleaner)} rows')\n",
    "print(f'Which makes sense since we had {polity_data_subset_iso_replace[\"iso3\"].isna().sum()} instances of NaNs in the polity2 column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dc318-2264-4e42-8ca3-f1cf5b85fac5",
   "metadata": {},
   "source": [
    "### Question 4: Check Polity2 <a class=\"anchor\" id=\"question4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d643-6867-4c1c-93f9-c3c38fb9d454",
   "metadata": {},
   "source": [
    "4a) Display the first and last year included in the dataset **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "57202c70-fe45-4f45-a29b-6a4761421972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest entry year: 1776, Latest entry year: 2020\n",
      "First row year: 1800, and last row year: 2018\n"
     ]
    }
   ],
   "source": [
    "# Answer 4a\n",
    "\n",
    "# Assuming the question is interpreted so that we are to find earliest and latest year recorded we have:\n",
    "print(f'Earliest entry year: {polity_data[\"year\"].min()}, Latest entry year: {polity_data[\"year\"].max()}')\n",
    "\n",
    "# Assuming the assignment is asking for the first and last year in the first and last row of the original dataset\n",
    "print(f'First row year: {polity_data.iloc[[0, -1]][\"year\"].values[0]}, and last row year: {polity_data.iloc[[0, -1]][\"year\"].values[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4593d98-be9b-45b3-86df-82e613ee851b",
   "metadata": {},
   "source": [
    "4b) What do the values in \"polity2\" represent? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4ecc-c2e6-4150-bf91-86bc067fd4a7",
   "metadata": {},
   "source": [
    "Answer 4b: \n",
    "\n",
    "`Polity2` is a revised version of the Polity score, which captures a regime authority on a `21-point` scale ranging from `-10` (hereditary monarchy) to `10` (consolidated democracy). `-66` are cases of foreign interruption and are treated as missing values. Whearas `-88` represents transitions. If a given country has the value of `-5` i 1990 and `+5` in 2000, it means that it has an annual increase of `+1`; and the converted scores are `1991: -4 1992: -3 ... 2000: +5` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a9072-8271-4336-9219-3c64a3f16e07",
   "metadata": {},
   "source": [
    "4c) Do we have weird values for polity2? If yes, why? What should we do about them? Transform the data accordingly. **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e710121-c355-4f34-8f81-187ccee789b7",
   "metadata": {},
   "source": [
    "Answer 4c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ef40f8d3-e7bd-49b9-9faa-a76931d0f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso3         0\n",
      "country      0\n",
      "year         0\n",
      "polity2    233\n",
      "dtype: int64\n",
      "[  9.   8.   0.  -3.  -4.  -7.   1.  -6.  -8. -10.  -1.  -2.  -9.  -5.\n",
      "   3.   5.   7.   2.   6.  10.   4. -88. -66.]\n",
      "[  9.   8.   0.  -3.  -4.  -7.   1.  -6.  -8. -10.  -1.  -2.  -9.  -5.\n",
      "   3.   5.   7.   2.   6.  10.   4.]\n",
      "HALLELUJA\n",
      "     iso3 country  year  polity2\n",
      "3607  CAN  Canada  1926     10.0\n",
      "     iso3 country  year  polity2\n",
      "6861  FRA  France  1940    -66.0\n",
      "6862  FRA  France  1941    -66.0\n",
      "6863  FRA  France  1942    -66.0\n",
      "6864  FRA  France  1943    -66.0\n"
     ]
    }
   ],
   "source": [
    "# Answer 4c\n",
    "\n",
    "# We have NaNs in polity2\n",
    "# Since we know that the NaNs from polity2 are the only ones left, we can just drop all NaNs.\n",
    "print(polity_data_ss_cleaner.isna().sum())\n",
    "\n",
    "df_cleaned = polity_data_ss_cleaner.dropna(subset='polity2', axis=0)\n",
    "\n",
    "# In addition we can see that we have values of -88 and -66. As this scale is supposed to range from -10 to 10, we should look a bit deeper if these values mean anything.\n",
    "# After some research i found some information : https://www.systemicpeace.org/inscr/p4manualv2016.pdf.\n",
    "# The Polity Project states that -66 \n",
    "print(df_cleaned['polity2'].unique())\n",
    "\n",
    "# Lets find the rows of those values\n",
    "polity66 = df_cleaned[df_cleaned['polity2'] == -66].index\n",
    "polity66_df = df_cleaned[df_cleaned['polity2'] == -66]\n",
    "polity88 = df_cleaned[df_cleaned['polity2'] == -88].index\n",
    "\n",
    "df_cleaned = df_cleaned.drop(index=polity66)\n",
    "df_cleaned = df_cleaned.drop(index=polity88)\n",
    "\n",
    "# Now we can see that we have the right values\n",
    "print(df_cleaned['polity2'].unique())\n",
    "\n",
    "# I can see that we have messed up the sorting of the data_frame. We can resolve this by using the sort_value function\n",
    "\n",
    "df_cleaned = df_cleaned.sort_values(['country', 'year']) \n",
    "\n",
    "\n",
    "print('HALLELUJA')\n",
    "print(df_cleaned.iloc[polity88])\n",
    "print(polity66_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b6f3a-11d9-477f-9fab-f7e644176c67",
   "metadata": {},
   "source": [
    "4d) Make a map that shows the number of observations of polity2 by country **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "53846332-57ef-4909-8367-5ffd2d737eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>polity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Vietnam North</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Yugoslavia</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  polity2\n",
       "0      Afghanistan      196\n",
       "1          Albania      105\n",
       "2          Algeria       57\n",
       "3           Angola       44\n",
       "4        Argentina      194\n",
       "..             ...      ...\n",
       "165  Vietnam North       23\n",
       "166          Yemen       29\n",
       "167     Yugoslavia       71\n",
       "168         Zambia       55\n",
       "169       Zimbabwe       39\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 4d\n",
    "\n",
    "pol_obs_per_country = df_cleaned.groupby(['country'])['polity2'].agg('count').reset_index()\n",
    "pol_obs_per_country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5258b-9ef6-4e9d-bf52-29a0d7ebc9b7",
   "metadata": {},
   "source": [
    "4e) Store the final dataframe (the one you obtained after 5d) in an object called df_pol **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7bb74cbc-5356-4e4b-b5b4-a5174c9ced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4e\n",
    "df_pol = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b6cd3-101d-4343-b76d-d97583fe33ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality of Government Environmental Indicators <a class=\"anchor\" id=\"qog\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58204e-f401-4b6e-b64a-c9d098faa0f2",
   "metadata": {},
   "source": [
    "The QoG Environmental Indicators dataset (QoG-EI) (Povitkina, Marina, Natalia Alvarado Pachon & Cem Mert Dalli. 2021). The Quality of Government Environmental Indicators Dataset, version Sep21. University of Gothenburg: The Quality of Government Institute, https://www.gu.se/en/quality-government), is a compilation of indicators measuring countries' environmental performance over time, including the presence and stringency of environmental policies, environmental outcomes (emissions, deforestation, etc.), and public opinion on the environment. Codebook and data are available [here](https://www.gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc77f2-25d1-41ce-930a-c25a05ac9cdc",
   "metadata": {},
   "source": [
    "### Question 5: Import the data and do few fixes <a class=\"anchor\" id=\"question5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959796a-3340-4231-838c-a4e2cba4262c",
   "metadata": {},
   "source": [
    "5a) Import data from the Quality of Government Environmental Indicators Dataset and display the variables types and the number of rows **(1 point)**\n",
    "<br>\n",
    "Hint: When you go on the webpage of the Environmental Indicators Dataset, you can directly import from a URL by copying the link address of the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "501ef767-dca9-426e-9e34-1335038b3b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable types: Unnamed: 0      int64\n",
      "cname          object\n",
      "ccode         float64\n",
      "year            int64\n",
      "cname_qog      object\n",
      "               ...   \n",
      "wvs_epmip     float64\n",
      "wvs_epmpp     float64\n",
      "wvs_imeop     float64\n",
      "wvs_pedp      float64\n",
      "wvs_ploem     float64\n",
      "Length: 415, dtype: object \n",
      " Number of rows: 15225\n"
     ]
    }
   ],
   "source": [
    "# Answer 5a\n",
    "url = 'https://www.qogdata.pol.gu.se/data/qog_ei_sept21.csv'\n",
    "df_qog = pd.read_csv(url, encoding='latin-1', low_memory=False)\n",
    "\n",
    "print(f'Variable types: {df_qog.dtypes} \\n Number of rows: {len(df_qog.index)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "88133c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15225"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_qog.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a8293-d098-4a79-a803-50d52f6b63b3",
   "metadata": {},
   "source": [
    "5b) Rename the variable \"ccodealp\" to \"iso3\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fc0e78d3-06b3-418c-81b8-05bbef009ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5b\n",
    "df_qog.rename(columns={'ccodealp': 'iso3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b34e8-0daa-4481-9b1b-61e7d318c571",
   "metadata": {},
   "source": [
    "5c) Check the type of the variables \"year\" and \"iso3\" are string, if not convert them to string **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c1993423-8edf-4bb0-8ea0-69034fce5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before convert \n",
      "Year datatype: int64\n",
      "iso3 datatype: object\n",
      "After convert \n",
      "Year datatype: string\n",
      "iso3 datatype: string\n"
     ]
    }
   ],
   "source": [
    "# Answer 5c\n",
    "print(f'Before convert \\nYear datatype: {df_qog[\"year\"].dtypes}')\n",
    "print(f'iso3 datatype: {df_qog[\"iso3\"].dtypes}')\n",
    "\n",
    "df_qog[['year', 'iso3']] = df_qog[['year', 'iso3']].astype('string')\n",
    "\n",
    "print(f'After convert \\nYear datatype: {df_qog[\"year\"].dtypes}')\n",
    "print(f'iso3 datatype: {df_qog[\"iso3\"].dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b61d4-55aa-439b-823f-67aad3f6fc16",
   "metadata": {},
   "source": [
    "### Question 6: Merge QOG and Polity5 ... issues with QOG? <a class=\"anchor\" id=\"question6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8af7f-3b38-4834-90b4-e1cbbb7b7359",
   "metadata": {},
   "source": [
    "6a) Get a subset of the dataframe that includes the variables \"cname\", \"iso3\", \"year\" and \"cckp_temp\", and display the number of rows. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8736cd36-ed4e-4dbd-96a9-c3d51bd343be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15225"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 6a\n",
    "\n",
    "df_qog_subset = df_qog[['cname', 'iso3',  'year', 'cckp_temp']]\n",
    "len(df_qog_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a0373-fab5-4346-bed7-3500ed9aced0",
   "metadata": {},
   "source": [
    "6b) Merge this subset (left) and the clean version of the polity data (right), using the argument how=\"left\". Was the merge succesfull? If yes, how many rows has the merged dataframe? Is it the same number of rows of the subset in 6a? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2bb2b0ba-fdd7-474a-9241-6d96e6eca6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 15225 rows, its the same amount of rows we saw in 6a\n"
     ]
    }
   ],
   "source": [
    "# Answer 6b\n",
    "\n",
    "merged = pd.merge(left=df_qog_subset, right=df_pol, how='left')\n",
    "print(f'With {len(merged)} rows, its the same amount of rows we saw in 6a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e5a50-5bda-4331-82a9-9cfe09a365cb",
   "metadata": {},
   "source": [
    "6c) Do the same by adding the argument validate=\"one-to-one\". Can you make some hypotheses on why you get an error? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fee8e0a9-75e7-4c37-80ad-3f5ddef8d602",
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in left dataset; not a one-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Answer 6c\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# By using the option validate='one-to-one', we get an error message which states that the merge keys are not unique. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y121sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Which makes sense which we for example have several rows in the same column with the same value.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y121sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m merge_one_to_one \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(left\u001b[39m=\u001b[39;49mdf_qog_subset, right\u001b[39m=\u001b[39;49mdf_pol, validate\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m1:1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    108\u001b[0m         left,\n\u001b[1;32m    109\u001b[0m         right,\n\u001b[1;32m    110\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    111\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    112\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    113\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    114\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    115\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    116\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    117\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    118\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    119\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    120\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:710\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[39m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[39m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[39mif\u001b[39;00m validate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(validate)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1432\u001b[0m, in \u001b[0;36m_MergeOperation._validate\u001b[0;34m(self, validate)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   1428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMerge keys are not unique in either left \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor right dataset; not a one-to-one merge\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1430\u001b[0m     )\n\u001b[1;32m   1431\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m left_unique:\n\u001b[0;32m-> 1432\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   1433\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMerge keys are not unique in left dataset; not a one-to-one merge\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1434\u001b[0m     )\n\u001b[1;32m   1435\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m right_unique:\n\u001b[1;32m   1436\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   1437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMerge keys are not unique in right dataset; not a one-to-one merge\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1438\u001b[0m     )\n",
      "\u001b[0;31mMergeError\u001b[0m: Merge keys are not unique in left dataset; not a one-to-one merge"
     ]
    }
   ],
   "source": [
    "# Answer 6c\n",
    "\n",
    "# By using the option validate='one-to-one', we get an error message which states that the merge keys are not unique. \n",
    "# Which makes sense which we for example have several rows in the same column with the same value.\n",
    "merge_one_to_one = pd.merge(left=df_qog_subset, right=df_pol, validate='1:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8da9ac-de08-460e-b364-40aaf5a9aa34",
   "metadata": {},
   "source": [
    "6d) Consider the subset of the QOG you obtained in 6a and write a code to (i) count the number of observations for the variable \"cckp_temp\" for each combination of iso3 and year, (ii) store the results in a dataframe. For example, the combination \"USA-2012\" should have 1 observation for \"cckp_temp\", so the result of your code should be 1. The code should do this for all iso3-year combinations of your subset dataframe, and store the results in a dataframe. **(1 point)**\n",
    "<br>\n",
    "Hint: it should not take you more than 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "593a4be8-0760-454d-8f55-e5e0bd18af49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 6d\n",
    "#cckp_temp_per_combination = df_qog_subset.groupby(['iso3', 'year'])['cckp_temp'].agg('size').reset_index()\n",
    "cckp_temp_per_combination = df_qog_subset.groupby(['iso3', 'year']).size().reset_index(name=\"cckp_temp_obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e92628-2085-4edf-aed4-8e6db647d9c6",
   "metadata": {},
   "source": [
    "6e) Use the code in 6d to write a function that displays all rows of the dataframe obtained in 6a that have more than one observation of \"cckp_temp\" for each iso3-year combination, and check if it works. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b66e42d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arun</td>\n",
       "      <td>CSE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arun</td>\n",
       "      <td>IT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bhuvi</td>\n",
       "      <td>CSE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bhuvi</td>\n",
       "      <td>IT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chandan</td>\n",
       "      <td>CSE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chandan</td>\n",
       "      <td>IT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name Department  Observation\n",
       "0     Arun        CSE            1\n",
       "1     Arun         IT            1\n",
       "2    Bhuvi        CSE            2\n",
       "3    Bhuvi         IT            1\n",
       "4  Chandan        CSE            1\n",
       "5  Chandan         IT            1"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "from cmath import nan\n",
    "import pandas as pd\n",
    "\n",
    "#create pandas DataFrame\n",
    "df = pd.DataFrame({'Name': ['Arun', 'Arun', 'Bhuvi', 'Bhuvi',\n",
    "\t\t\t\t\t\t\t'Bhuvi', 'Chandan', 'Chandan'],\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t'Department':['CSE', 'IT', 'CSE', 'CSE',\n",
    "\t\t\t\t\t\t\t\t'IT', 'IT', 'CSE'],\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t'Funds': [1100, 5, 700, 600, 600, 500, 1200]})\n",
    "\n",
    "# create a group using groupby\n",
    "group = df.groupby(['Name', 'Department'])\n",
    "\n",
    "# size of group to count observations\n",
    "group = group.size()\n",
    "\n",
    "# make a column name\n",
    "group.reset_index(name='Observation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e953896a-28a5-4d38-8ad3-93027c5c4698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   cname iso3  year  cckp_temp\n",
      "14400                         Uzbekistan  UZB  1962        NaN\n",
      "14401                         Uzbekistan  UZB  1963        NaN\n",
      "14402                         Uzbekistan  UZB  1964        NaN\n",
      "14403                         Uzbekistan  UZB  1965        NaN\n",
      "14404                         Uzbekistan  UZB  1966        NaN\n",
      "14405                         Uzbekistan  UZB  1967        NaN\n",
      "14406                         Uzbekistan  UZB  1968        NaN\n",
      "14407                         Uzbekistan  UZB  1969        NaN\n",
      "14408                         Uzbekistan  UZB  1970        NaN\n",
      "14409                         Uzbekistan  UZB  1971        NaN\n",
      "14410                         Uzbekistan  UZB  1972        NaN\n",
      "14411                         Uzbekistan  UZB  1973        NaN\n",
      "14412                         Uzbekistan  UZB  1974        NaN\n",
      "14413                         Uzbekistan  UZB  1975        NaN\n",
      "14414                         Uzbekistan  UZB  1976        NaN\n",
      "14415                         Uzbekistan  UZB  1977        NaN\n",
      "14416                         Uzbekistan  UZB  1978        NaN\n",
      "14417                         Uzbekistan  UZB  1979        NaN\n",
      "14418                         Uzbekistan  UZB  1980        NaN\n",
      "14419                         Uzbekistan  UZB  1981        NaN\n",
      "14420                         Uzbekistan  UZB  1982        NaN\n",
      "14421                         Uzbekistan  UZB  1983        NaN\n",
      "14422                         Uzbekistan  UZB  1984        NaN\n",
      "14423                         Uzbekistan  UZB  1985        NaN\n",
      "14424                         Uzbekistan  UZB  1986        NaN\n",
      "14425                         Uzbekistan  UZB  1987        NaN\n",
      "14426                         Uzbekistan  UZB  1988        NaN\n",
      "14427                         Uzbekistan  UZB  1989        NaN\n",
      "14428                         Uzbekistan  UZB  1990        NaN\n",
      "14429                         Uzbekistan  UZB  1991        NaN\n",
      "14430                         Uzbekistan  UZB  1992  12.316667\n",
      "14431                         Uzbekistan  UZB  1993  11.766667\n",
      "14432                         Uzbekistan  UZB  1994  12.133333\n",
      "14433                         Uzbekistan  UZB  1995  13.683333\n",
      "14434                         Uzbekistan  UZB  1996  12.125000\n",
      "14435                         Uzbekistan  UZB  1997  13.266667\n",
      "14436                         Uzbekistan  UZB  1998  12.841667\n",
      "14437                         Uzbekistan  UZB  1999  13.775000\n",
      "14438                         Uzbekistan  UZB  2000  13.675000\n",
      "14439                         Uzbekistan  UZB  2001  13.650000\n",
      "14440                         Uzbekistan  UZB  2002  13.650000\n",
      "14441                         Uzbekistan  UZB  2003  12.883333\n",
      "14442                         Uzbekistan  UZB  2004  14.291667\n",
      "14443                         Uzbekistan  UZB  2005  13.825000\n",
      "14444                         Uzbekistan  UZB  2006  13.550000\n",
      "14445                         Uzbekistan  UZB  2007  13.758333\n",
      "14446                         Uzbekistan  UZB  2008  13.100000\n",
      "14447                         Uzbekistan  UZB  2009  13.391667\n",
      "14448                         Uzbekistan  UZB  2010  14.100000\n",
      "14449                         Uzbekistan  UZB  2011  12.841667\n",
      "14450                         Uzbekistan  UZB  2012  12.866667\n",
      "14451                         Uzbekistan  UZB  2013  14.166667\n",
      "14452                         Uzbekistan  UZB  2014  12.591667\n",
      "14453                         Uzbekistan  UZB  2015  13.941667\n",
      "14454                         Uzbekistan  UZB  2016  14.308333\n",
      "14455                         Uzbekistan  UZB  2017  13.616667\n",
      "14456                         Uzbekistan  UZB  2018  13.450000\n",
      "14457                         Uzbekistan  UZB  2019  14.200000\n",
      "14458                         Uzbekistan  UZB  2020  13.566667\n",
      "14459  Venezuela, Bolivarian Republic of  VEN  1946  25.225000\n",
      "14460  Venezuela, Bolivarian Republic of  VEN  1947  25.608333\n",
      "14461  Venezuela, Bolivarian Republic of  VEN  1948  25.216667\n",
      "14462  Venezuela, Bolivarian Republic of  VEN  1949  25.033333\n",
      "14463  Venezuela, Bolivarian Republic of  VEN  1950  24.691667\n",
      "14464  Venezuela, Bolivarian Republic of  VEN  1951  25.341667\n",
      "14465  Venezuela, Bolivarian Republic of  VEN  1952  25.550000\n",
      "14466  Venezuela, Bolivarian Republic of  VEN  1953  25.408333\n",
      "14467  Venezuela, Bolivarian Republic of  VEN  1954  25.008333\n",
      "14468  Venezuela, Bolivarian Republic of  VEN  1955  24.916667\n",
      "14469  Venezuela, Bolivarian Republic of  VEN  1956  24.916667\n",
      "14470  Venezuela, Bolivarian Republic of  VEN  1957  25.333333\n",
      "14471  Venezuela, Bolivarian Republic of  VEN  1958  25.916667\n",
      "14472  Venezuela, Bolivarian Republic of  VEN  1959  25.433333\n",
      "14473  Venezuela, Bolivarian Republic of  VEN  1960  25.433333\n",
      "14474  Venezuela, Bolivarian Republic of  VEN  1961  25.425000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'bool' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb Cell 70\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39miloc[df_index]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y125sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(more_than_one_cckp_temp(df_qog_subset)\u001b[39m.\u001b[39mto_string())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(df_qog_subset[df_qog_subset[(\u001b[39m\"\u001b[39;49m\u001b[39miso3\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mUZB\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m&\u001b[39;49m (\u001b[39m\"\u001b[39;49m\u001b[39myear\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m==\u001b[39m \u001b[39m1962\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'bool' and 'str'"
     ]
    }
   ],
   "source": [
    "# Answer 6e\n",
    "def more_than_one_cckp_temp(df):\n",
    "\tdf_grouped = df.groupby([\"iso3\", \"year\"])[\"cckp_temp\"].agg(\"size\").reset_index()\n",
    "\tdf_index = df_grouped[df_grouped.cckp_temp > 1].index\n",
    "\treturn df.iloc[df_index]\n",
    "\n",
    "print(more_than_one_cckp_temp(df_qog_subset).to_string())\n",
    "\n",
    "print(df_qog_subset[df_qog_subset[(\"iso3\" == 'UZB') & (\"year\") == 1962]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190da03-b34c-4566-8aec-5a1a540ac660",
   "metadata": {},
   "source": [
    "6f) Which countries have more than one observation for each iso3-year combination? Deal with these countries in the subset dataframe created in 6a to make sure you no longer have double observations for iso3-year combinations, and check that after your fix this is actually the case. **(1 point)**\n",
    "<br>\n",
    "Hint: should we keep a country with all missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6d960c4a-b755-448c-8952-aee2e6eee878",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Answer 6f\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pcw/Documents/GitHub/class_datascience/Notebooks/Assignment/individual_assignment/01_individual_assignment.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m more_than_one_cckp_temp(df_qog_subset)\u001b[39m.\u001b[39;49miloc[\u001b[39m22\u001b[39;49m]\u001b[39m.\u001b[39;49mcckp_temp\u001b[39m.\u001b[39;49msize() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Answer 6f\n",
    "more_than_one_cckp_temp(df_qog_subset).iloc[22].cckp_temp.size() > 1\n",
    "\n",
    "#more_than_one_cckp_temp(df_qog_subset).to_csv('more_than_one_cckp_temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae70541-6427-4f83-bd05-37ef68baf5cd",
   "metadata": {},
   "source": [
    "6g) If your check went well, now you can perform the same operation directly in the QOG dataframe (not in the substed dataframe created in 6a). How many rows does now the QOG dataframe has? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f20b2-04e4-46d0-94f6-e580913ddfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd12e1-799e-4e4c-8d13-db496fb5bab4",
   "metadata": {},
   "source": [
    "### Question 7: Merge QOG and Polity5 ... issues with Polity5? <a class=\"anchor\" id=\"question7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72692a86-a9ab-44bb-bb56-b3c22e0829c4",
   "metadata": {},
   "source": [
    "7a) Merge the cleaned QOG dataframe (left) and the Polity dataframe (right) using the options how=\"left\" and validate=\"one_to_one\". Does it work? Why? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82261ca5-c3ec-49f6-8de8-be1b14943cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95740ccf-88d7-46ee-82ab-f1a8b42d9722",
   "metadata": {},
   "source": [
    "7b) Use the function you wrote in 6e to check what's wrong in the \"clean\" version of Polity **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356409a0-73e8-41ac-af75-c2f6a462c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d8f5b-10f5-4540-b714-99b77f3e5203",
   "metadata": {},
   "source": [
    "7c) Drop or fix the countries that create troubles directly in the \"clean\" version of Polity and motivate your choices. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb945c-418a-4eee-bdd3-2dce12246196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88282d66-3aa1-4fa4-b7cc-b448c649052c",
   "metadata": {},
   "source": [
    "7d) Try now to merge the \"clean-clean\" versions of qog and Polity (the ones you obtained in 7g and 8c) always using the options how=\"left\" and validate=\"one_to_one\". Does it work, and why? How many rows has the resulting merged dataframe? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e52b0f-7484-4656-82bd-8de4cee284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8479c-556a-4c9b-b89f-a8f714e888ad",
   "metadata": {},
   "source": [
    "### Question 8: Clean the merged dataframe <a class=\"anchor\" id=\"question8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936854f-7882-47bc-a2c0-cb39b53128b0",
   "metadata": {},
   "source": [
    "8a) In the merged dataframe, order the columns so that you have the \"index\" variables first and the variables with actual values last. **(1 point)**\n",
    "<br>\n",
    "Hint: index variables are \"iso3\", \"year\" and other similar variables you can find, and the variables with actual values are \"polity2\", \"cckp_temp\" and other similar variables you can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e92ad2-8007-4a4b-a47f-44c040ccfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39c4e8-6f99-47c9-9d32-4196e4184537",
   "metadata": {},
   "source": [
    "8b) Rename \"cname\" as \"country\" and \"country\" as \"country_polity\". **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2cccd-473d-462e-9b2f-726aa6763d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353db63e-08d7-41df-9bdf-e0aa20174569",
   "metadata": {},
   "source": [
    "8c) Save the clean merged dataframe as a csv in a subfolder called \"clean_data\" in your working directory **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a684c82-6df7-480f-9374-a2d4e7ec069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2840-c690-4b3e-8e4c-0025101bdc62",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa01e2b-dc8a-49ae-a19b-8c42bd0f2e57",
   "metadata": {},
   "source": [
    "In this section you will define a research question and perform a preliminary Exploratory Data Analysis (EDA) to address - or better, start addressing - the question at hand. This exercise will be done along the lines of the analysis done by our own Quentin Gallea in \"*A recipe to empirically answer any question quickly*\" ([Towards Data Science, 2022](https://towardsdatascience.com/a-recipe-to-empirically-answer-any-question-quickly-22e48c867dd5)). In this article, Quentin shows the first steps of an EDA that aims to explore whether heat waves have pushed governments to implement regulations against climate change (causal link). The logic is that, as it gets hotter and hotter, governments become more aware of climate change, and the problems it can cause to society, and start addressing it. In Quentin's analysis, heat waves (proxied by temperature) is the \"main explanatory variable\", rainfall is the \"explanatory variable for heterogeneity\", and regulations against climate change (proxied by the Environmental Policy Stringency Index) is the \"outcome variable\". He finds that indeed countries with relatively high temperatures have implemented more regulations against climate change. This is true especially when rainfall levels are low, as when it does not rain the damage of extreme heat is more evident to legislators, who therefore apply stricter regulations against these phenomenons.\n",
    "<br>\n",
    "<br>\n",
    "In this exercise, you will be asked to do a similar analysis on a research question of your choice, using at least two of the variables of the dataset we have created in the former questions (QOG + Polity). For example, \"what is the average temperature in 2010?\" is not a valid research question (univariate), while \"what is the impact of high temperatures on the stringency of climate regulations?\" is a valid research question (at least bivariate). As before, we will ask you some (this time more general and open) questions, and you should report your answer in the cells below each question. Use a mix of markdown and code cells to answer (markdown for text and code for graphs and tables). We should be able to run all the graphs, i.e. screenshots of graphs are not accepted. Note that for now we have put only one markdown cell and one code cell for the answer, but feel free to add as many cells as you need.\n",
    "<br>\n",
    "Beyond the python code, we will grade the interpretations of the results and the coding decision you make.\n",
    "<br>\n",
    "<br>\n",
    "Let your creativity guide you and let's have some fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97f39-3b6d-4546-8871-b136d122854c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 9: Selecting the ingredients (how I select the variables) <a class=\"anchor\" id=\"question9\"></a>\n",
    "We have saved the clean merged data that resulted from the previous questions in \"clean_data_prepared_EDA\" (it should be the same of the one you saved in \"clean_data\"). Import the clean merged data from \"clean_data_prepared_EDA\" using this [link](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/clean_data_prepared_EDA/df_qog_polity_merged.csv). Explore the variables in the newly obtained dataframe by checking the documentation of QOG and Polity. Then, define a research question that addresses a causal link between at least two of these variables. Describe the research question, why you are addressing it and the variables of interest (outcome variable, main explanatory variable and explanatory variable for heterogeneity). **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df577a5-f0f1-43e8-aeb1-0708fe53892b",
   "metadata": {},
   "source": [
    "Answer 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575ca1f-de5a-4b03-a51a-7f0cc5fa18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b5531-0329-4817-a341-d1a1bb96ef2d",
   "metadata": {},
   "source": [
    "### Question 10: Picking the right quantity of each ingredient (how I select my sample) <a class=\"anchor\" id=\"question10\"></a>\n",
    "Explore the data availability of your variables of interest and select a clean sample for the analysis. Describe this sample with the help of summary-statistics tables and maps. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef40ba-ff3a-4983-99c7-151be2f9622e",
   "metadata": {},
   "source": [
    "Answer 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb262470-32d1-4d2c-af1c-8616daed69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4434c1-4ca5-44af-a24c-67a1b8d20cc6",
   "metadata": {},
   "source": [
    "### Question 11: Tasting and preparing the ingredients (univariate analysis) <a class=\"anchor\" id=\"question11\"></a>\n",
    "Do an univariate analysis for each variable you have chosen (outcome variable, main explanatory variable and explanatory variable for heterogeneity):\n",
    "- Prepare the variable, for example see if you need to transform the data further, i.e. log-transform, define a categorical variable, deal with outliers, etc.\n",
    "- Understand the nature of the variable, i.e. continuous, categorical, binary, etc., which then allows to pick the right statistical tool in the bivariate analysis.\n",
    "- Get an idea of the variable's behaviour across time and space.\n",
    "\n",
    "Describe these steps and the conclusions you can draw with the help of histograms, tables, maps and line graphs. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef687c9b-69c5-49b0-adb3-2aac7406112c",
   "metadata": {},
   "source": [
    "Answer 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fffac2-d33c-410f-9f10-c190a4c59641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ad4a-70fc-4f39-bffb-cf10dd93205f",
   "metadata": {},
   "source": [
    "### Question 12: Cooking the ingredients together (bivariate analysis) <a class=\"anchor\" id=\"question12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c658-8c22-4bb0-b1ef-4b5860f6cc31",
   "metadata": {},
   "source": [
    "Considering the \"nature\" of your variables (continuous, categorical, binary, etc.), pick the right tool / tools for a preliminary bivariate analysis, i.e. correlation tables, bar/line graphs, scatter plots, etc. Use these tools to describe your preliminary bivariate analysis and your findings. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bb04c-9223-4e3d-b815-2d7ee3657f00",
   "metadata": {},
   "source": [
    "Answer 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c0962-c661-4649-b8f3-e721e7ef66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 12:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0a05d-004a-42f3-b472-b7a808cd0dc1",
   "metadata": {},
   "source": [
    "### Question 13: Tasting the new recipe (conclusion) <a class=\"anchor\" id=\"question13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b861d-d4d5-42b1-94ad-5aa33f9bf7a2",
   "metadata": {},
   "source": [
    "Explain what you learned, the problem faced, what would you do next (you can suggest other data you would like to have etc). **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536aef2-a8df-4e17-9089-01ba8d93c029",
   "metadata": {},
   "source": [
    "Answer 13:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c967b75bd3da4530419091f2a82585a1448630d30358f0f328fd8248d7345ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
