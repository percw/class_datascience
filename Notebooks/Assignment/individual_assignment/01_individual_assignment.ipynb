{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795860f2-eabf-40d1-954c-843dcf672a7d",
   "metadata": {},
   "source": [
    "# MGT-499 Statistics and Data Science - Individual Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58faf4-db28-41c1-9e6d-ead96d328eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here what you need\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5761d-3238-4e69-951f-6fea4557ef41",
   "metadata": {},
   "source": [
    "This notebook contains the individual assignment for the class MGT-499 Statistics and Data Science. Important information:\n",
    "- **Content**: the assignment is divided in two main parts, namely data cleaning (2 datasets) and Exploratory Data Analysis, for a total of 13 main questions (see table of contents). Some of these main questions are divided in sub questions. In the first part, the questions are very specific, while in the second part they are more open.\n",
    "- **Deadline**: Tuesday 8th of November at 23:59. \n",
    "- **Final Output**: a Jupyter notebook, which we (teachers) can run. \n",
    "- **Answering the Questions**: you will find the questions in markdown cells below. Under each of these cells, you will find a cell / cells for answers. Type there your answer. For the answer to be correct, the cell with the answer must run without error (unless specified). You can use markdown cells for the answers that require text.\n",
    "- **Submission**: submit the assignment on Moodle, under [Individual Assignment](https://moodle.epfl.ch/mod/assign/view.php?id=1222846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e43ccf-9ed6-44ea-8dd3-184cb9e7c499",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Content\n",
    "- [Polity5 Dataset](#polity5)  \n",
    "    - [Question 1: Import the data and get a first glance](#question1)\n",
    "    - [Question 2: Select some variables](#question2)\n",
    "    - [Question 3: Missing Values](#question3)\n",
    "    - [Question 4: Check Polity2](#question4)\n",
    "- [Quality of Government (QOG) Environmental Indicators Dataset](#qog)  \n",
    "    - [Question 5: Import the data and do few fixes](#question5)\n",
    "    - [Question 6: Merge QOG and Polity5 ... first attempt](#question6)\n",
    "    - [Question 7: Merge QOG and Polity5 ... second attempt](#question7)\n",
    "    - [Question 8: Clean the merged dataframe](#question8)\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "    - [Question 9: Selecting the ingredients for the recipe (how I select the variables)](#question9)  \n",
    "    - [Question 10: Picking the right quantity of each ingredient (how I select my sample)](#question10)\n",
    "    - [Question 11: Tasting and preparing the ingredients (univariate analysis)](#question11)\n",
    "    - [Question 12: Cooking the ingredients together (bivariate analysis)](#question12)\n",
    "    - [Question 13: Tasting the new recipe (conclusion)](#question13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142f738-6239-4e12-9c65-fd27b4db73ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polity5 data <a class=\"anchor\" id=\"polity5\"></a>\n",
    "\n",
    "Polity5 is a widely used democracy scale. The raw data as well as the codebook are available [here](http://www.systemicpeace.org/inscrdata.html). For this assignment, we have modified a bit the original version, for example we have added the iso3 code for countries to make you save time. You can find the modified version [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903da7f-480e-4777-a4ef-9ab94b09e473",
   "metadata": {},
   "source": [
    "### Question 1: import the data and get a first glance <a class=\"anchor\" id=\"question1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f6829-6c8f-451a-9670-4d1c7a103c12",
   "metadata": {},
   "source": [
    "1a) Import the csv 'polity2_iso3.csv' (file provided in the link [here](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv)) as a panda dataframe (ignore the warning message) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7e4014-e55c-4994-a633-61a8fdf1e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1a\n",
    "url = 'https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/data/polity2_iso3.csv'\n",
    "polity_data = pd.read_csv(url, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd738c61-10ca-4439-8bcf-20e6987e3e5f",
   "metadata": {},
   "source": [
    "1b) Display the first 10 rows **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10544e0c-33b5-4b90-ad68-4cfe8d6c40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1b\n",
    "polity_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6decfca-afb8-4c77-881c-8fb78d96e68d",
   "metadata": {},
   "source": [
    "1c) Display the data types of all the variables included in the data **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa768541-03f9-424a-a690-d6132298f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1c\n",
    "polity_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ee31a-7cc9-44d2-b7f8-242f6ee5ebfc",
   "metadata": {},
   "source": [
    "1d) By looking at your answer in 1c, what is the difference between the different types of variables? Why the type of some variables is defined as object? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97f628-71b6-4aac-9c9c-596773557131",
   "metadata": {},
   "source": [
    "Answer 1d:\n",
    "\n",
    "We can see that we have four different dataypes: `object`, `float64` and `int64`. `Object` is  the pandas type for mixed values s.a. strings and numbers. In python the equivivalent  type is `string`. `Float64` refers to numeric characters with decimals. If columns contain numbers and NaN pandas will defualt to `float64`. And for `int64` is for integer numbers, and the 64 refers to memory allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfba84f-b897-4fcb-880d-9d8995045239",
   "metadata": {},
   "source": [
    "### Question 2. Select some variables <a class=\"anchor\" id=\"question2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a9776a-26ed-4154-af73-0e2b337e9e74",
   "metadata": {},
   "source": [
    "2a) Create a subset dataframe that contains the variables 'iso3', 'country', 'year', 'polity2' and display it **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd0a39-386d-4397-93eb-8eb7e0415a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2a\n",
    "polity_data_subset = (polity_data[['iso3', 'country', 'year', 'polity2']]).copy()\n",
    "polity_data_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4883d-8f9e-4b1f-9ce4-c62267090287",
   "metadata": {},
   "source": [
    "2b) Display the type of the variable \"year\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc6b73-70d9-42c0-9cd1-716033325a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2b\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639b2d3-b5e6-40f3-93c9-6547bcdcb814",
   "metadata": {},
   "source": [
    "2c) Convert the variable \"year\" to string **(1 point)**\n",
    "<br>\n",
    "Hint: if you get a warning message of the type \"SettingWithCopyWarning\", it is because you did not subset the data in the right way. Go back to your class notes and check the different ways to subset a dataframe, and try again. If you do it correctly, you will not get the warning message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d8f60-9875-40be-9f78-0c7c2837a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 2c\n",
    "polity_data_subset['year'] = polity_data_subset['year'].astype('string')\n",
    "polity_data_subset['year'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0babf3-0e33-4e13-9289-523ecef5e004",
   "metadata": {},
   "source": [
    "### Question 3: Missing Values <a class=\"anchor\" id=\"question3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb19a0f-bd7c-4d9c-bdfa-05e55e4eb26f",
   "metadata": {},
   "source": [
    "3a) Subset the rows that have iso3 missing and display **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb48bb3-a92a-4565-8a5c-f22f642f2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3a\n",
    "iso_missing = polity_data_subset[polity_data_subset['iso3'].isna()]\n",
    "iso_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b352b-c860-4b2c-bca3-5437c2bbaf23",
   "metadata": {},
   "source": [
    "3b) Display the countries that have missing iso3. What can you tell by looking at them? Any similarities? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9760a-a4a6-4826-b377-49ff300662f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3b\n",
    "iso_missing_contries = iso_missing['country']\n",
    "print(f'They seem to be old countries, or old country names.\\n\\n{iso_missing_contries.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41b9a2-2c70-41c6-b891-95e01f2a74a5",
   "metadata": {},
   "source": [
    "3c) Display the countries with missing iso3 from 2011. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408fff2-6493-4dff-9294-ef1c564315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3c\n",
    "# Interpreting the question so that we take the contries missing iso3 from 2011 onwards\n",
    "global df_missing_iso3_since_2011\n",
    "global df_missing_iso3_since_2011_list\n",
    "\n",
    "df_missing_iso3_since_2011 = iso_missing[iso_missing['year'].astype(int) >= 2011]\n",
    "df_missing_iso3_since_2011_list = sorted(df_missing_iso3_since_2011['country'].unique())\n",
    "df_missing_iso3_since_2011_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9a6b6-2151-4c5e-8a8a-ea9810905642",
   "metadata": {},
   "source": [
    "3d) Display the rows for which the column \"country\" contains the word \"Serbia\". By looking at the result, can you tell what happened to Serbia in 2006? **(1 point)**\n",
    "<br>\n",
    "Hint: the most general way of doing this is to use a combination of re.search and list comprehension. To display the full subset, you can use print(df.to_string())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953ca64-d67b-4c94-8df6-5077efa68814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3d\n",
    "polity_data_subset_serbia = polity_data_subset[polity_data_subset['country'].str.contains(pat='Serbia', case=False)]\n",
    "print(polity_data_subset_serbia.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684448da",
   "metadata": {},
   "source": [
    "We can see that the country referred to as Serbia, reappeared in 2006, \n",
    "This is due to a name change following Montenegro and Serbias decleration of independence of their previous union named `Serbia and Montenegro`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd97b-0aaa-4bca-affb-22f3c0ca387c",
   "metadata": {},
   "source": [
    "3e) Write a function that does the operation in 3d and use it to display the subset that has the word \"sudan\" (all lower cap) in country. Then do the same for the word \"vietnam\" (all lower cap). **(1 point)**\n",
    "<br>\n",
    "Hint: options of functions can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217b330-72ef-4d38-8a66-1849d12f7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3e\n",
    "\n",
    "# Function find_country\n",
    "# input: dataframe, column, name\n",
    "# output: df containting the specified string in the column 'country'\n",
    "# making sure that the type is correct, helping me later if use the wrong type\n",
    "\n",
    "def find_rows_with_pattern(df:pd.DataFrame, column:str, name:str):\n",
    "\ttry:\n",
    "\t\treturn df[df[column].str.contains(pat=name, case=False)]\n",
    "\texcept TypeError as e:\n",
    "\t\tprint(f'Not a valid datatype: {e}.\\nUse {pd.DataFrame} and {str} as option type parameters')\n",
    "\n",
    "df_sudan = find_rows_with_pattern(polity_data_subset, 'country', 'sudan')\n",
    "df_vietnam = find_rows_with_pattern(polity_data_subset, 'country', 'vietnam')\n",
    "\n",
    "print(df_sudan.to_string())\n",
    "print(df_vietnam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a0adc-6104-4dff-baa4-cbc8259183b4",
   "metadata": {},
   "source": [
    "3f) Replace nan values in iso3 with correct iso3 for the 5 countries found in 3c from 2011 onwards, and display the subset with the fixed values to check that everything worked. **(1 point)**\n",
    "<br>\n",
    "Hint: the correct iso3 for these 5 countries are \"ETH\",\"MNE\",\"SRB\",\"SDN\",\"VNM\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab9532-5a03-46fe-9db7-170e8b087957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3f\n",
    "\n",
    "# Storing the correct iso3 values in a list\n",
    "iso3_code_missing = ('ETH', 'MNE', 'SRB', 'SDN', 'VNM')\n",
    "\n",
    "# Creating a dict to look up correct iso3 values with list from 3c\n",
    "iso3_dict = dict(zip(df_missing_iso3_since_2011_list, iso3_code_missing))\n",
    "\n",
    "# Copying the politydata to work on\n",
    "polity_data_subset_iso_replace = polity_data_subset.copy()\n",
    "\n",
    "# Function: replace(df, dct, replaced)\n",
    "# input: df: dataframe, dct: dictionary to loop through, replaced: item to be replaced\n",
    "# manipulates in place\n",
    "\n",
    "def replace(df, dct, replaced, from_year):\n",
    "    for key, item in dct.items():\n",
    "        df.loc[(df['country'] == key) & (df['year'].astype(int) >= from_year)] = df.loc[(\n",
    "            df['country'] == key) & (df['year'].astype(int) >= 2011)].replace(replaced, item)\n",
    "\n",
    "\n",
    "# Calling the function and telling which value i want to replace\n",
    "replace(polity_data_subset_iso_replace, iso3_dict, np.nan, 2011)\n",
    "\n",
    "# Using the indexes of the subset created in 3c to check if we have the correct countrycodes\n",
    "polity_data_subset_iso_replace.iloc[df_missing_iso3_since_2011.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa210c-b46f-46ff-a8da-d72d95bff196",
   "metadata": {},
   "source": [
    "3g) Drop the remaining rows which have nan in \"iso3' and display the new number of rows of the dataframe (how many are they?) **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cea78-0af1-405f-aeed-41dfc8fee4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3g\n",
    "\n",
    "# Dropping NaNs in the iso3 column\n",
    "polity_data_ss_cleaner = polity_data_subset_iso_replace.dropna(subset='iso3')\n",
    "\n",
    "# Number of rows, and making sure that the data is consistent\n",
    "print(f'Before removing rows with NaNs in column \"iso3\" we had: {len(polity_data_subset_iso_replace)} rows')\n",
    "print(f'Now we have: {len(polity_data_ss_cleaner)} rows')\n",
    "print(f'Which means that we removed: {len(polity_data_subset_iso_replace) - len(polity_data_ss_cleaner)} rows')\n",
    "print(f'Which makes sense since we had {polity_data_subset_iso_replace[\"iso3\"].isna().sum()} instances of NaNs in the polity2 column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313dc318-2264-4e42-8ca3-f1cf5b85fac5",
   "metadata": {},
   "source": [
    "### Question 4: Check Polity2 <a class=\"anchor\" id=\"question4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d643-6867-4c1c-93f9-c3c38fb9d454",
   "metadata": {},
   "source": [
    "4a) Display the first and last year included in the dataset **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57202c70-fe45-4f45-a29b-6a4761421972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4a\n",
    "\n",
    "# Assuming the question is interpreted so that we are to find earliest and latest year recorded we have:\n",
    "print(f'Earliest entry year: {polity_data[\"year\"].min()}, Latest entry year: {polity_data[\"year\"].max()}')\n",
    "\n",
    "# Assuming the assignment is asking for the first and last year in the first and last row of the original dataset\n",
    "print(f'First row year: {polity_data.iloc[[0, -1]][\"year\"].values[0]}, and last row year: {polity_data.iloc[[0, -1]][\"year\"].values[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4593d98-be9b-45b3-86df-82e613ee851b",
   "metadata": {},
   "source": [
    "4b) What do the values in \"polity2\" represent? **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c4ecc-c2e6-4150-bf91-86bc067fd4a7",
   "metadata": {},
   "source": [
    "Answer 4b: \n",
    "\n",
    "`Polity2` is a revised version of the Polity score, which captures a regime authority on a `21-point` scale ranging from `-10` (hereditary monarchy) to `10` (consolidated democracy). `-66` are cases of foreign interruption and are treated as missing values. Whearas `-88` represents transitions. If a given country has the value of `-5` i 1990 and `+5` in 2000, it means that it has an annual increase of `+1`; and the converted scores are `1991: -4 1992: -3 ... 2000: +5` \n",
    "\n",
    "The documentation I used is [here](https://www.systemicpeace.org/inscr/p4manualv2016.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a9072-8271-4336-9219-3c64a3f16e07",
   "metadata": {},
   "source": [
    "4c) Do we have weird values for polity2? If yes, why? What should we do about them? Transform the data accordingly. **(1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e710121-c355-4f34-8f81-187ccee789b7",
   "metadata": {},
   "source": [
    "Answer 4c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40f8d3-e7bd-49b9-9faa-a76931d0f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4c\n",
    "\n",
    "# We can see that we have NaNs in polity2\n",
    "print(f'Number of NaNs in the df per column: \\n {polity_data_ss_cleaner.isna().sum()}')\n",
    "print(f'\\nThe unique values of polity2: \\n {polity_data_ss_cleaner.polity2.unique()}')\n",
    "\n",
    "# To repeat:\n",
    "# -66 : cases of foreign “interruption” are treated as “system missing.”\n",
    "# -88 : Cases of “transition” are prorated across the span of the transition. \n",
    "# So the NaNs may be there for a reason...\n",
    "\n",
    "# Creating a copy df to work on\n",
    "df_cleaned = polity_data_ss_cleaner.copy()\n",
    "\n",
    "# Lets find the rows with -66 and -88\n",
    "polity_66_88_index = df_cleaned[(df_cleaned.polity2 == -66) | (df_cleaned.polity2 == -88)].index\n",
    "print(f'\\nRows with -66 and -88:\\n{polity_data_subset.iloc[polity_66_88_index].to_string()}')\n",
    "\n",
    "# In addition -88 values should be treated as missing values, as i have looked into the data for other occupied countries during the world wars\n",
    "# We see that they have NaNs and not -66. I will therefor change the -66 to NaN\n",
    "df_cleaned.loc[df_cleaned.polity2 == -66] = df_cleaned.loc[(df_cleaned.polity2 == -66)].replace(-66, 0)\n",
    "\n",
    "# As Belgium has -88 for the first row, and all the nearest following years has score -4 i will change this value to -4\n",
    "df_cleaned.loc[df_cleaned.polity2 == -88] = df_cleaned.loc[(df_cleaned.polity2 == -88)].replace(-88, np.float64(-4))\n",
    "\n",
    "# Printing the current unique polity2 values to verify changes\n",
    "print(f'\\nThe new unique values of polity2: \\n {df_cleaned.polity2.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1b6f3a-11d9-477f-9fab-f7e644176c67",
   "metadata": {},
   "source": [
    "4d) Make a map that shows the number of observations of polity2 by country **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53846332-57ef-4909-8367-5ffd2d737eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4d\n",
    "\n",
    "pol_obs_per_country = df_cleaned.groupby(['iso3'])['polity2'].size().reset_index()\n",
    "pol_obs_map = px.choropleth(pol_obs_per_country, locations='iso3',\n",
    "                    title='Number of polity2 observations by country',\n",
    "                    locationmode='ISO-3',\n",
    "                    color='polity2', \n",
    "                    hover_name='iso3',\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "pol_obs_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5258b-9ef6-4e9d-bf52-29a0d7ebc9b7",
   "metadata": {},
   "source": [
    "4e) Store the final dataframe (the one you obtained after 5d) in an object called df_pol **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb74cbc-5356-4e4b-b5b4-a5174c9ced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 4e\n",
    "df_pol = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b6cd3-101d-4343-b76d-d97583fe33ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality of Government Environmental Indicators <a class=\"anchor\" id=\"qog\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58204e-f401-4b6e-b64a-c9d098faa0f2",
   "metadata": {},
   "source": [
    "The QoG Environmental Indicators dataset (QoG-EI) (Povitkina, Marina, Natalia Alvarado Pachon & Cem Mert Dalli. 2021). The Quality of Government Environmental Indicators Dataset, version Sep21. University of Gothenburg: The Quality of Government Institute, https://www.gu.se/en/quality-government), is a compilation of indicators measuring countries' environmental performance over time, including the presence and stringency of environmental policies, environmental outcomes (emissions, deforestation, etc.), and public opinion on the environment. Codebook and data are available [here](https://www.gu.se/en/quality-government/qog-data/data-downloads/environmental-indicators-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc77f2-25d1-41ce-930a-c25a05ac9cdc",
   "metadata": {},
   "source": [
    "### Question 5: Import the data and do few fixes <a class=\"anchor\" id=\"question5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959796a-3340-4231-838c-a4e2cba4262c",
   "metadata": {},
   "source": [
    "5a) Import data from the Quality of Government Environmental Indicators Dataset and display the variables types and the number of rows **(1 point)**\n",
    "<br>\n",
    "Hint: When you go on the webpage of the Environmental Indicators Dataset, you can directly import from a URL by copying the link address of the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ef767-dca9-426e-9e34-1335038b3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5a\n",
    "url = 'https://www.qogdata.pol.gu.se/data/qog_ei_sept21.csv'\n",
    "df_qog = pd.read_csv(url, encoding='latin-1')\n",
    "\n",
    "print(f'Variable types: {df_qog.dtypes} \\n\\n Number of rows: {len(df_qog)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a8293-d098-4a79-a803-50d52f6b63b3",
   "metadata": {},
   "source": [
    "5b) Rename the variable \"ccodealp\" to \"iso3\" **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e78d3-06b3-418c-81b8-05bbef009ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5b\n",
    "df_qog.rename(columns={'ccodealp': 'iso3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b34e8-0daa-4481-9b1b-61e7d318c571",
   "metadata": {},
   "source": [
    "5c) Check the type of the variables \"year\" and \"iso3\" are string, if not convert them to string **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1993423-8edf-4bb0-8ea0-69034fce5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 5c\n",
    "print(f'Before convert \\nYear datatype: {df_qog.year.dtypes}')\n",
    "print(f'iso3 datatype: {df_qog.iso3.dtypes}')\n",
    "\n",
    "df_qog[['year', 'iso3']] = df_qog[['year', 'iso3']].astype('string')\n",
    "\n",
    "print(f'After convert \\nYear datatype: {df_qog.year.dtypes}')\n",
    "print(f'iso3 datatype: {df_qog.iso3.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b61d4-55aa-439b-823f-67aad3f6fc16",
   "metadata": {},
   "source": [
    "### Question 6: Merge QOG and Polity5 ... issues with QOG? <a class=\"anchor\" id=\"question6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8af7f-3b38-4834-90b4-e1cbbb7b7359",
   "metadata": {},
   "source": [
    "6a) Get a subset of the dataframe that includes the variables \"cname\", \"iso3\", \"year\" and \"cckp_temp\", and display the number of rows. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736cd36-ed4e-4dbd-96a9-c3d51bd343be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6a\n",
    "\n",
    "df_qog_subset = df_qog[['cname', 'iso3',  'year', 'cckp_temp']]\n",
    "len(df_qog_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a0373-fab5-4346-bed7-3500ed9aced0",
   "metadata": {},
   "source": [
    "6b) Merge this subset (left) and the clean version of the polity data (right), using the argument how=\"left\". Was the merge succesfull? If yes, how many rows has the merged dataframe? Is it the same number of rows of the subset in 6a? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2b0ba-fdd7-474a-9241-6d96e6eca6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6b\n",
    "\n",
    "merged = pd.merge(left=df_qog_subset, right=df_pol, how='left')\n",
    "print(f'Yes - With {len(merged)} rows, its the same amount of rows at we saw in 6a')\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e5a50-5bda-4331-82a9-9cfe09a365cb",
   "metadata": {},
   "source": [
    "6c) Do the same by adding the argument validate=\"one-to-one\". Can you make some hypotheses on why you get an error? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8e0a9-75e7-4c37-80ad-3f5ddef8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6c\n",
    "merge_one_to_one = pd.merge(left=df_qog_subset, right=df_pol, validate='1:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724398f",
   "metadata": {},
   "source": [
    "\n",
    "By using the option validate='one-to-one', we get an error message which states that the merge keys are not unique. \n",
    "Which makes sense since we for example have several rows in the same column with the same value.There may be ambiguity in the keys in which the merge uses to match the two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8da9ac-de08-460e-b364-40aaf5a9aa34",
   "metadata": {},
   "source": [
    "6d) Consider the subset of the QOG you obtained in 6a and write a code to (i) count the number of observations for the variable \"cckp_temp\" for each combination of iso3 and year, (ii) store the results in a dataframe. For example, the combination \"USA-2012\" should have 1 observation for \"cckp_temp\", so the result of your code should be 1. The code should do this for all iso3-year combinations of your subset dataframe, and store the results in a dataframe. **(1 point)**\n",
    "<br>\n",
    "Hint: it should not take you more than 2 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a4be8-0760-454d-8f55-e5e0bd18af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6d\n",
    "cckp_temp_per_combination = df_qog_subset.groupby(['iso3', 'year'])['cckp_temp'].size().reset_index()\n",
    "cckp_temp_per_combination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e92628-2085-4edf-aed4-8e6db647d9c6",
   "metadata": {},
   "source": [
    "6e) Use the code in 6d to write a function that displays all rows of the dataframe obtained in 6a that have more than one observation of \"cckp_temp\" for each iso3-year combination, and check if it works. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e953896a-28a5-4d38-8ad3-93027c5c4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6e\n",
    "\n",
    "def more_than_one_combination(df, c1, c2, obs):\n",
    "\tdf = df.groupby([c1, c2])[obs].size().reset_index()\n",
    "\tdf = df[df[obs].astype(int) > 1]\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination1 = 'iso3'\n",
    "combination2 = 'year'\n",
    "observation = 'cckp_temp'\n",
    "\n",
    "more_than_one_combination(df_qog_subset, combination1, combination2, observation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190da03-b34c-4566-8aec-5a1a540ac660",
   "metadata": {},
   "source": [
    "6f) Which countries have more than one observation for each iso3-year combination? Deal with these countries in the subset dataframe created in 6a to make sure you no longer have double observations for iso3-year combinations, and check that after your fix this is actually the case. **(1 point)**\n",
    "<br>\n",
    "Hint: should we keep a country with all missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d960c4a-b755-448c-8952-aee2e6eee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6f\n",
    "\n",
    "# Using the previous function to get the countries with more than one iso3-year combination\n",
    "countries = more_than_one_combination(df_qog_subset, 'iso3', 'year', 'cckp_temp')\n",
    "\n",
    "# Getting the iso3 code for that particualar country\n",
    "iso3_duplicate_country = countries.iso3.unique()[0]\n",
    "\n",
    "# Creating a df to show all the data with the iso3-year combiantion constraints \n",
    "iso3_duplicate_df = df_qog_subset[df_qog_subset.iso3 == iso3_duplicate_country]\n",
    "\n",
    "# Inspecting the values, and seeing that all cckp_temp values for North Vietnam are NaN\n",
    "print(iso3_duplicate_df.to_string())\n",
    "\n",
    "# We saw that we only have NaN values for North Vietnam - so we lets find the indexes of these rows\n",
    "# In addiiton the Polity5 dont have any country names North Vietnam so i think we can remove these\n",
    "north_vietnam_indexes = df_qog_subset[df_qog_subset.cname == 'North Vietnam'].index\n",
    "\n",
    "# Based on the indexes we can drop these rows\n",
    "df_qog_cleaned = df_qog_subset.drop(index=north_vietnam_indexes)\n",
    "\n",
    "# Now we can check whether we have any duplicated by running the function from 6e again.\n",
    "more_than_one_combination(df_qog_cleaned,'iso3', 'year', 'cckp_temp').empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635717c",
   "metadata": {},
   "source": [
    "We saw that we only have NaN values for North Vietnam, In addiiton the Polity5 dont have any country names North Vietnam that is why i dropped these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae70541-6427-4f83-bd05-37ef68baf5cd",
   "metadata": {},
   "source": [
    "6g) If your check went well, now you can perform the same operation directly in the QOG dataframe (not in the substed dataframe created in 6a). How many rows does now the QOG dataframe has? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f20b2-04e4-46d0-94f6-e580913ddfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6g\n",
    "\n",
    "# Using the function from 6e with the original dataset\n",
    "more_than_one_iso_year_combination_df = more_than_one_combination(df_qog, 'iso3', 'year', 'cckp_temp')\n",
    "\n",
    "# By inspecting the df it looks like we the same countries here. North Vietnam and Viet Nam.\n",
    "print(more_than_one_iso_year_combination_df.to_string())\n",
    "\n",
    "# Lets again find the indexes\n",
    "north_vietnam_indexes = df_qog[df_qog.cname == 'North Vietnam'].index\n",
    "\n",
    "# Dropping the North Vietnam indexes\n",
    "df_qog = df_qog.drop(index=north_vietnam_indexes)\n",
    "\n",
    "print(f'New length: {len(df_qog)}')\n",
    "\n",
    "# We can now see that we dont have any multiple combinations of iso3 and year anymore\n",
    "more_than_one_combination(df_qog, 'iso3', 'year', 'cckp_temp').empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd12e1-799e-4e4c-8d13-db496fb5bab4",
   "metadata": {},
   "source": [
    "### Question 7: Merge QOG and Polity5 ... issues with Polity5? <a class=\"anchor\" id=\"question7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72692a86-a9ab-44bb-bb56-b3c22e0829c4",
   "metadata": {},
   "source": [
    "7a) Merge the cleaned QOG dataframe (left) and the Polity dataframe (right) using the options how=\"left\" and validate=\"one_to_one\". Does it work? Why? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82261ca5-c3ec-49f6-8de8-be1b14943cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7a\n",
    "merge_qog_polity5 = pd.merge(left=df_qog, right=df_pol, how='left', validate='one_to_one')\n",
    "\n",
    "# We get the error message that the keys are not unique in the right dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95740ccf-88d7-46ee-82ab-f1a8b42d9722",
   "metadata": {},
   "source": [
    "7b) Use the function you wrote in 6e to check what's wrong in the \"clean\" version of Polity **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356409a0-73e8-41ac-af75-c2f6a462c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7b\n",
    "\n",
    "# By displaying the df_pol with iso3 value MNE we see that Kosovo has the wrong iso3 value. \n",
    "# This makes sense regarding the error message we got in 7a\n",
    "polity_combination_issues_polity = more_than_one_combination(df_pol, 'iso3', 'year', 'polity2')\n",
    "polity_combination_issues_country = more_than_one_combination(df_pol, 'iso3', 'year', 'country')\n",
    "print(f\"Checking which iso3-year combinations has several observations of polity2: \\n {polity_combination_issues_polity}\")\n",
    "print(f\"Checking which iso3-year combinations has several observations of countries: \\n {polity_combination_issues_country}\")\n",
    "print(f'Checking the countries with iso3 code MNE: {df_pol[df_pol.iso3 == \"MNE\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d8f5b-10f5-4540-b714-99b77f3e5203",
   "metadata": {},
   "source": [
    "7c) Drop or fix the countries that create troubles directly in the \"clean\" version of Polity and motivate your choices. **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb945c-418a-4eee-bdd3-2dce12246196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7c\n",
    "# Kosovo does not officially have a iso3 value but we can use XKX set by the European Commission\n",
    "# OR we can choose to drop it completely as the QoG dataset does not include data on Kosova at all\n",
    "# And since we only have values from 2011-2018 for Sudan-North and in QoG dataset dont have any\n",
    "# values for Sudan-North/North-Sudan/Sudan North/North Sudan at all, we should drop these.\n",
    "\n",
    "print(f'Checking if there are severeal countries with iso3 code SDN in QoG: {df_qog[df_qog.iso3 == \"SDN\"].cname.unique()}')\n",
    "print(f\"Checking if there is any data on Sudan-North in QoG: {find_rows_with_pattern(df_qog, 'cname', 'sudan-north').cname.unique()}\")\n",
    "print(f\"Checking if there is any data on North-Sudan in QoG: {find_rows_with_pattern(df_qog, 'cname', 'north-sudan').cname.unique()}\")\n",
    "print(f\"Checking if there is any data on North Sudan in QoG: {find_rows_with_pattern(df_qog, 'cname', 'sudan north').cname.unique()}\")\n",
    "print(f\"Checking if there is any data on Sudan North  in QoG: {find_rows_with_pattern(df_qog, 'cname', 'north sudan').cname.unique()}\")\n",
    "\n",
    "# I have devided to drop Kosovo and Sudan-North\n",
    "# Lets find the indexes of these rows\n",
    "kosovo_indexes = df_pol[df_pol.country == 'Kosovo'].index\n",
    "sudan_north_indexes = df_pol[df_pol.country == 'Sudan-North'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f543f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Based on the indexes we can drop these rows\n",
    "df_pol = df_pol.drop(index=kosovo_indexes)\n",
    "df_pol = df_pol.drop(index=sudan_north_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88282d66-3aa1-4fa4-b7cc-b448c649052c",
   "metadata": {},
   "source": [
    "7d) Try now to merge the \"clean-clean\" versions of qog and Polity (the ones you obtained in 7g and 8c) always using the options how=\"left\" and validate=\"one_to_one\". Does it work, and why? How many rows has the resulting merged dataframe? **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e52b0f-7484-4656-82bd-8de4cee284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7d\n",
    "merge_qog_polity5 = pd.merge(left=df_qog, right=df_pol, how='left', on=['iso3', 'year'], validate='one_to_one')\n",
    "len(merge_qog_polity5)\n",
    "\n",
    "# It works as there is no longer any ambiguioty with the combination of iso3 and year in either of the dataframes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be8479c-556a-4c9b-b89f-a8f714e888ad",
   "metadata": {},
   "source": [
    "### Question 8: Clean the merged dataframe <a class=\"anchor\" id=\"question8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936854f-7882-47bc-a2c0-cb39b53128b0",
   "metadata": {},
   "source": [
    "8a) In the merged dataframe, order the columns so that you have the \"index\" variables first and the variables with actual values last. **(1 point)**\n",
    "<br>\n",
    "Hint: index variables are \"iso3\", \"year\" and other similar variables you can find, and the variables with actual values are \"polity2\", \"cckp_temp\" and other similar variables you can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e92ad2-8007-4a4b-a47f-44c040ccfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8a\n",
    "\n",
    "# Displaying all the column names to get an overview\n",
    "column_list = merge_qog_polity5.columns.tolist()\n",
    "#print(column_list)\n",
    "\n",
    "# Popping the columns we want to re-order\n",
    "iso3_column = merge_qog_polity5.pop('iso3')\n",
    "year_column = merge_qog_polity5.pop('year')\n",
    "year_country = merge_qog_polity5.pop('country')\n",
    "\n",
    "# Inserting columns in the specified order\n",
    "merge_qog_polity5.insert(2, 'iso3', iso3_column)\n",
    "merge_qog_polity5.insert(3, 'year', year_column)\n",
    "merge_qog_polity5.insert(4, 'country', year_country)\n",
    "\n",
    "column_list_after = merge_qog_polity5.columns.tolist()\n",
    "#print(column_list_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39c4e8-6f99-47c9-9d32-4196e4184537",
   "metadata": {},
   "source": [
    "8b) Rename \"cname\" as \"country\" and \"country\" as \"country_polity\". **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2cccd-473d-462e-9b2f-726aa6763d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8b\n",
    "merge_qog_polity5.rename(columns={'cname': 'country', 'country': 'country_polity'}, inplace=True)\n",
    "merge_qog_polity5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353db63e-08d7-41df-9bdf-e0aa20174569",
   "metadata": {},
   "source": [
    "8c) Save the clean merged dataframe as a csv in a subfolder called \"clean_data\" in your working directory **(1 point)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a684c82-6df7-480f-9374-a2d4e7ec069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 8c\n",
    "\n",
    "# Removing index columns\n",
    "#merge_qog_polity5 = merge_qog_polity5.pop('Unnamed: 0')\n",
    "\n",
    "# Cleaning path if exists\n",
    "if os.path.exists('clean_data'):\n",
    "\tos.remove('clean_data/clean_data.csv')\n",
    "\tos.rmdir('clean_data')\n",
    "\n",
    "# Creating folder and exporting csv\n",
    "os.makedirs('clean_data')\n",
    "merge_qog_polity5.to_csv('clean_data/clean_data.csv', index=False)\n",
    "\n",
    "# I also want to add that i have done a lot of comparison check between the two csv files.\n",
    "# I learnt that using the .eq or .equeal method on float number does not work very well,\n",
    "# as these numbers are \"floating\", 1.0005 may in fact be 1.00005000102. \n",
    "# So i used np.isclose(a, b) - which works between a certain very small range.count\n",
    "# I'm happy to say that the two datasets looks identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f2840-c690-4b3e-8e4c-0025101bdc62",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa01e2b-dc8a-49ae-a19b-8c42bd0f2e57",
   "metadata": {},
   "source": [
    "In this section you will define a research question and perform a preliminary Exploratory Data Analysis (EDA) to address - or better, start addressing - the question at hand. This exercise will be done along the lines of the analysis done by our own Quentin Gallea in \"*A recipe to empirically answer any question quickly*\" ([Towards Data Science, 2022](https://towardsdatascience.com/a-recipe-to-empirically-answer-any-question-quickly-22e48c867dd5)). In this article, Quentin shows the first steps of an EDA that aims to explore whether heat waves have pushed governments to implement regulations against climate change (causal link). The logic is that, as it gets hotter and hotter, governments become more aware of climate change, and the problems it can cause to society, and start addressing it. In Quentin's analysis, heat waves (proxied by temperature) is the \"main explanatory variable\", rainfall is the \"explanatory variable for heterogeneity\", and regulations against climate change (proxied by the Environmental Policy Stringency Index) is the \"outcome variable\". He finds that indeed countries with relatively high temperatures have implemented more regulations against climate change. This is true especially when rainfall levels are low, as when it does not rain the damage of extreme heat is more evident to legislators, who therefore apply stricter regulations against these phenomenons.\n",
    "<br>\n",
    "<br>\n",
    "In this exercise, you will be asked to do a similar analysis on a research question of your choice, using at least two of the variables of the dataset we have created in the former questions (QOG + Polity). For example, \"what is the average temperature in 2010?\" is not a valid research question (univariate), while \"what is the impact of high temperatures on the stringency of climate regulations?\" is a valid research question (at least bivariate). As before, we will ask you some (this time more general and open) questions, and you should report your answer in the cells below each question. Use a mix of markdown and code cells to answer (markdown for text and code for graphs and tables). We should be able to run all the graphs, i.e. screenshots of graphs are not accepted. Note that for now we have put only one markdown cell and one code cell for the answer, but feel free to add as many cells as you need.\n",
    "<br>\n",
    "Beyond the python code, we will grade the interpretations of the results and the coding decision you make.\n",
    "<br>\n",
    "<br>\n",
    "Let your creativity guide you and let's have some fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97f39-3b6d-4546-8871-b136d122854c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 9: Selecting the ingredients (how I select the variables) <a class=\"anchor\" id=\"question9\"></a>\n",
    "We have saved the clean merged data that resulted from the previous questions in \"clean_data_prepared_EDA\" (it should be the same of the one you saved in \"clean_data\"). Import the clean merged data from \"clean_data_prepared_EDA\" using this [link](https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/clean_data_prepared_EDA/df_qog_polity_merged.csv). Explore the variables in the newly obtained dataframe by checking the documentation of QOG and Polity. Then, define a research question that addresses a causal link between at least two of these variables. Describe the research question, why you are addressing it and the variables of interest (outcome variable, main explanatory variable and explanatory variable for heterogeneity). **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df577a5-f0f1-43e8-aeb1-0708fe53892b",
   "metadata": {},
   "source": [
    "Answer 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bb830",
   "metadata": {},
   "source": [
    "#### Climate Responsibility\n",
    "\n",
    "Going back in time, from the start of the industrial revolution to now, highly industrialized countries have benefited greatly from polluting without consequence. High emission industries has created powerful nations with huge economies. So, if we aggregate total CO2 emission per capita per country, do the high polluters take responsibility for their historic and ongoing climate impact? I want to investigate the relationship between total CO2 emission per capita and degree of environmental action. Are the high-polluting countries paying the price or are they still exploiting their influence and power to further enhance their dominance?\n",
    "\n",
    "Furthermore, one could argue that a country’s motivation to incorporate environment legislation comes from selfishness. Let me clarify with an imaginative example: Let's say a highly industrialized successful country faces a lot of climate threats such as extreme weather, wildfires, and flooding. Then it is in the country’s best interest to drive environmental politics. I would in this regard call this national climate responsibility, but not global per se. So to investigate this problem I will look at how the Climate Change Issue within each country effects the plot. The Climate Change Issue addresses to which extent each country faces climate change challenges.\n",
    "\n",
    "As this is a personal question of mine, I’m very curious to see if I can find any correlation, causality, and or discover other underlying driving factors. I initially wanted to use the “Environmental Policy Performance Index” but as the country availability is almost limited to the the western countries, and to withstand the use of the same variable as Quentin I will use the “Climate change related tax revenue given in % of GDP\" as my outcome variable. I find this suiting as it in this case directly translates to “paying for wrongdoing”.\n",
    "\n",
    "So, to sum up:\n",
    "\n",
    "- Outcome: Climate change related tax revenue (% of GDP) (`oecd_cctr_gdp`) *<cite>[1][1]</cite>\n",
    "- Explanatory variable: CO2 emissions per capita (`edgar_co2pc`) *<cite>[2][2]</cite>\n",
    "- Additional explanatory variable: Climate Change Issue Category (`epi_cch`) *<cite>[3][3]</cite>\n",
    "\n",
    "[1]: oe.cd/pine\n",
    "[2]: https://www.sgi-network.org/2020/Downloads\n",
    "[3]: https://epi.envirocenter.yale.edu/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b5531-0329-4817-a341-d1a1bb96ef2d",
   "metadata": {},
   "source": [
    "### Question 10: Picking the right quantity of each ingredient (how I select my sample) <a class=\"anchor\" id=\"question10\"></a>\n",
    "Explore the data availability of your variables of interest and select a clean sample for the analysis. Describe this sample with the help of summary-statistics tables and maps. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef40ba-ff3a-4983-99c7-151be2f9622e",
   "metadata": {},
   "source": [
    "Answer 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7d8fb",
   "metadata": {},
   "source": [
    "The table below reveals that we have 180 observations for `epi_cch` - which is consistent with what the documentation said. It's an assessment of 8 indicators done in 2019 measuring climate challenge. The score varies from 0 to 100. As this i a new variable, it may not express the historic climate challenge a country faces. But as climate challenges are somewhat consistent i think that a country facing a lot of threats in 2019 may also have been so historically. So i will continue with this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575ca1f-de5a-4b03-a51a-7f0cc5fa18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/edoardochiarotti/class_datascience/main/Notebooks/Assignment/individual_assignment/clean_data_prepared_EDA/df_qog_polity_merged.csv'\n",
    "df_qog_polity_merged = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb262470-32d1-4d2c-af1c-8616daed69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10:\n",
    "# Subsetting and picking the variables i want to investigate\n",
    "df_subset = df_qog_polity_merged[['country', 'iso3', 'year', 'oecd_cctr_gdp', 'edgar_co2pc', 'epi_cch']]\n",
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see all notna values for epi_cch - consistent with the documentation - all from 2019.\n",
    "df_subset[df_subset.epi_cch.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6012f",
   "metadata": {},
   "source": [
    "Now lets see how dense our `Tax%GDP` data is. Between 2000 and 2017 we have mean above 80 - meaning we have Carbon Tax % of GDP for over 80 countries. This is quite good. I will use this time interval in my studies. Since climate change and its reactive measures did not get any widespread attention before Al Gore addressed GHG and its alarming warming effects in early 1990s, i will also neglect the effects on not using any data prior to 2000. I'm making an assumption that the  climate change tax as a percentage of GDP in % was relatively small prior to 1990s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596be62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[pd.notnull(df_subset['oecd_cctr_gdp'])].groupby(['year']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But since we only have data for epi_cch from 2019. I will take this data out of the dataframe, remove all NaNs and then we can merge later on when we have aggregated the other datasets.\n",
    "\n",
    "climate_challenge_df = df_subset[['iso3', 'year' , 'country', 'epi_cch']]\n",
    "\n",
    "climate_challenge_clean = climate_challenge_df.dropna()\n",
    "\n",
    "climate_challage_iso3_codes = climate_challenge_clean.iso3.unique()\n",
    "\n",
    "# These are the countries that has a value for epi_cch (climate challenge issue) from 2019 and the countries we will work with.\n",
    "climate_challage_iso3_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And for the time being we can pop the epi_cch column from our QoG_polity_subset\n",
    "df_subset.pop('epi_cch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433aa29a",
   "metadata": {},
   "source": [
    "Here is a table for the CO2 emission per capita for each country. The first recordings are from 1970. Which can make my hypothesis a bit hard to answer, as emissions before 1970 are not in this dataset. I tried looking online to see any datasets to merge in, and use. I found a reliable source at https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions. My plan now is to use these values to give a more historically correct picture. The CO2 data has a corresponding GitHub page here: https://github.com/owid/co2-data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ac260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset[pd.notnull(df_subset['edgar_co2pc'])].groupby(['year']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbb6ab",
   "metadata": {},
   "source": [
    "### Fetching new data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching data from Our World In Data.\n",
    "# This set is one of the most comprehensive data collections of total historically CO2 emissions.\n",
    "url = 'https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.csv'\n",
    "df_co2 = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b0148",
   "metadata": {},
   "source": [
    "Doing some housekeeping (subsetting a useable dataframe and changing iso_code to iso3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2_subset = df_co2[['country', 'year', 'iso_code', 'population', 'co2']].copy()\n",
    "\n",
    "df_co2_subset.rename(columns={'iso_code': 'iso3'}, inplace=True)\n",
    "\n",
    "# Extracting the countries we have from climate_challage_iso3_codes.\n",
    "df_co2_subset_country_limited = df_co2_subset[df_co2_subset.iso3.isin(climate_challage_iso3_codes)].copy()\n",
    "len(df_co2_subset_country_limited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column with co2 per capita and converting the scale so we have co2_per_capita and total co2 in tons\n",
    "df_co2_subset_country_limited['co2'] = df_co2_subset_country_limited['co2']*1000000\n",
    "df_co2_subset_country_limited['co2_per_capita'] =  df_co2_subset_country_limited['co2']/df_co2_subset_country_limited['population']\n",
    "\n",
    "# And giving it a cleaner name...\n",
    "df_co2_final = df_co2_subset_country_limited.copy()\n",
    "df_co2_final = df_co2_final.dropna()\n",
    "\n",
    "df_co2_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198cd450",
   "metadata": {},
   "source": [
    "Now i think we have a good working foundation for our emission data. \n",
    "### Moving to the QoG and Polity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec73305",
   "metadata": {},
   "source": [
    "Lets work further with our qog_polity dataset. I want to extract the data from 2000-2018. And then sum up the mean Climate change related tax revenue (% of GDP) per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset_2000_2018 = df_subset[(df_subset.year >= 2000) & (df_subset.year <= 2018)]\n",
    "\n",
    "# Dropping the lackful emission column\n",
    "df_subset_2000_2018_slim = df_subset_2000_2018.drop(columns='edgar_co2pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets also here limit the countries to the ones we found in climate_challage_iso3_codes\n",
    "\n",
    "df_qog_pol_clean = df_subset_2000_2018_slim[df_subset_2000_2018_slim.iso3.isin(climate_challage_iso3_codes)].copy()\n",
    "df_qog_pol_clean.describe()\n",
    "\n",
    "# Wait .... hmmm - the mean for Tax to climate change as in % of GDP is 76%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76faae83",
   "metadata": {},
   "source": [
    "\n",
    "#### A mistake?\n",
    "...Wait a minute, how can the `% of GDP` from Climate Change tax be over 100% and have an mean of 76%? This seems off. I will check the definition for the variable once again.\n",
    "\n",
    "> Climate change-related tax revenue as a percentage of gross domestic product (GDP). Includes\n",
    "taxes, fees and charges, tradable permits, deposit-refund systems, subsidies, and voluntary approaches related to the domain of climate change.\n",
    "\n",
    "\n",
    "In my view this should probably be lower...\n",
    "\n",
    "I will go to the data source <cite>[OECD][1]</cite> and see if the values there are the same. I found this <cite>[Compare Your Country (OECD data)][1]</cite> a simple graph showing that the numbers in the `QoG_pol` dataset is wrong (or at least its something odd here)\n",
    "\n",
    "Then i found this site where i could download the data i wanted. At  <cite>[Stats.OECD.org][1]</cite>, I downloaded it as i couldn't find any other places where this data was accessible by url or through an api.\n",
    "\n",
    "#### Its 80mb...\n",
    "\n",
    "So i did some adjustments to the file before committing it to my public `data_folder` in the `class_datascience` repo on GitHub.It should be perfectly open for everyone, with all right reserved to OECD.\n",
    "At first i downloaded the whole file locally. And then investigated what could be removed. I found out that there were maney categories for the environmental tax. All tax bases', 'Energy', 'Transport', 'Pollution', 'Resources. I'm interested in all tax bases, so that should shrank the data file a lot.\n",
    "\n",
    "I'm leaving the code i used below, but commented out...\n",
    "\n",
    "[1]:http://oe.cd/pine\n",
    "[2]:https://www.compareyourcountry.org/environmental-taxes/en/1/183/default\n",
    "[3]:https://stats.oecd.org/Index.aspx?DataSetCode=ERTR#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ee2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the original dataset that QoG used, its huge...\n",
    "#climate_tax = pd.read_csv('data/ERTR_29102022172652539.csv', low_memory=False)\n",
    "\n",
    "# Checking the keys\n",
    "#climate_tax.Category.unique()\n",
    "\n",
    "# Narrowing\n",
    "#climate_tax_total = climate_tax[climate_tax.Category == 'All tax bases']\n",
    "\n",
    "# Exporting\n",
    "#climate_tax_total.to_csv('oecd_climate_tax_total.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6d1742",
   "metadata": {},
   "source": [
    "That shrunk the filesize to 15mb, which is better. Ill uploead that on my public data_science repo, and then we can continue to invest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/percw/class_datascience/main/Notebooks/Assignment/individual_assignment/data/oecd_climate_tax_total.csv'\n",
    "climate_tax = pd.read_csv(url, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc5225",
   "metadata": {},
   "source": [
    "Now we need to do some cleaning and housekeeping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837df33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a lot of combinations countrycode-year combinations. \n",
    "more_than_one_combination(climate_tax, 'COU', 'Year', 'Value')\n",
    "\n",
    "# Here we can see what the keys looks like\n",
    "climate_tax.columns\n",
    "\n",
    "# I will check one country to start with to see if i can see that all of these values are about\n",
    "switzerland = climate_tax[climate_tax.Country == 'Switzerland']\n",
    "switzerland\n",
    "\n",
    "# Looks like there are different categories. I want Climate change. Lets filter on that\n",
    "switzerland_cc = switzerland[switzerland['Environmental domain'] == 'Climate change']\n",
    "switzerland_cc\n",
    "\n",
    "# And the variable im looking for is Tax revenue, % of GDP\n",
    "switzerland_cc_tax = switzerland_cc[switzerland_cc['Variable'] == 'Tax revenue, % of GDP']\n",
    "\n",
    "more_than_one_combination(switzerland_cc_tax, 'COU', 'Year', 'Value')\n",
    "# After this we dont have any ambiguity in our country-year combination.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac8024",
   "metadata": {},
   "source": [
    "I have to look at the definition in the codebook given by QoG again.\n",
    "\n",
    "> Climate change-related tax revenue as a percentage of gross domestic product (GDP). Includes\n",
    "taxes, fees and charges, tradable permits, deposit-refund systems, subsidies, and voluntary approaches related to the domain of climate change.\n",
    "\n",
    "It looks like QoG database used the `Tax revenue, % of total environmentally related tax revenue` value instead of `Tax revenue, % of GDP`. This value is much higher as it is the percentage of Tax related to climate change OVER environmental related tax revenue. Now it makes sense. Lets try to extract the correct values. I may be wrong here, overlooked something or misinterpreted the definition. But if not - i may have found an error in the QoG database.\n",
    "\n",
    "So - to find the value that I want i need to define my subset with a couple of constraints.\n",
    "\n",
    "- Environmental domain : Climate change\n",
    "- Unit : Percentage\n",
    "- Variable : Tax revenue, % of GDP\n",
    "- CAT : TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9685621",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "climate_tax = climate_tax[(climate_tax['Environmental domain'] == 'Climate change') & (climate_tax['Unit'] == 'Percentage') & (climate_tax['Variable'] == 'Tax revenue, % of GDP') & (climate_tax['CAT'] == 'TOT')]\n",
    "\n",
    "# Great, it worked for the whole dataset as well.\n",
    "more_than_one_combination(climate_tax, 'COU', 'Year', 'Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can start exploring the new dataset and extracting what we want\n",
    "\n",
    "ct_df = climate_tax[['COU', 'Year', 'Country', 'Value']]\n",
    "ct_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f552778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having - % seems odd. Lets look a bit further\n",
    "\n",
    "ct_df[ct_df.Value == -1.540000]\n",
    "\n",
    "# Mexico seems to have several - values.\n",
    "ct_df[ct_df.Country == 'Mexico']\n",
    "\n",
    "# Lets see if any other countries have that as well\n",
    "ct_df[ct_df.Value < 0]\n",
    "\n",
    "# Its only mexico. I dont think these data are accurate so i may remove them...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ... before we remove them, i will only extract the countries we have in climate_challage_iso3_codes. \n",
    "# Maybe Mexico is not there. Which means that we do not have to do anything.\n",
    "\n",
    "ct_df = ct_df[ct_df.COU.isin(climate_challage_iso3_codes)]\n",
    "ct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d56b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok - so Mexico is still there, lets drop it.\n",
    "\n",
    "mexico_indexes = ct_df[ct_df.Country == 'Mexico'].index\n",
    "\n",
    "ct_df_clean = ct_df.drop(index=mexico_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602992e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i want to rename the columns to match the QoG data\n",
    "ct_df_clean.rename(columns={'COU' : 'iso3', 'Year': 'year', 'Country' : 'country', 'Value' : 'oecd_cctr_gdp'}, inplace=True)\n",
    "ct_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7383d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i want to see how dense my data is\n",
    "\n",
    "ct_df_clean[pd.notnull(ct_df_clean['oecd_cctr_gdp'])].groupby(['year']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f6233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should see if there are any countries with very few tax registrations\n",
    "df_oecd_cctr_gdp_count = ct_df_clean[pd.notnull(ct_df_clean['oecd_cctr_gdp'])].groupby(['country']).size().reset_index(name=\"counts\")\n",
    "df_oecd_cctr_gdp_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85519fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# These countries has less than 20 observations, i will remove thme \n",
    "countries = df_oecd_cctr_gdp_count[df_oecd_cctr_gdp_count.counts < 20].country.unique()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c in countries:\n",
    "\tc_index = ct_df_clean[ct_df_clean.country == c].index\n",
    "\tct_df_clean = ct_df_clean.drop(index=c_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets also make the oecd tax data sub subset from 2000 to 2018\n",
    "climate_tax_df = ct_df_clean[(ct_df_clean.year >= 2000) & (ct_df_clean.year <= 2018)]\n",
    "climate_tax_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41b2a9",
   "metadata": {},
   "source": [
    "#### Lets merge and then aggregate\n",
    "\n",
    "So we now have 3 different datasets.\n",
    "\n",
    "- climate_tax_df : range 2000-2018. Climate Change tax % of GDP\n",
    "- climate_challenge_clean : 2019. Score of Climate challenge a country faces\n",
    "- df_co2_final : range 1750-2020. Total and per capita annual emission per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0910ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tax_co2_df = pd.merge(left=df_co2_final, right=climate_tax_df, how='left', validate='1:1')\n",
    "tax_co2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3d07c",
   "metadata": {},
   "source": [
    "Here is the merged data (now called: `tax_co2_cc_df`) with the Climate Challenge Issue score from 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bab6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_co2_cc_df = pd.merge(left=tax_co2_df, right=climate_challenge_clean, how='left')\n",
    "tax_co2_cc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4434c1-4ca5-44af-a24c-67a1b8d20cc6",
   "metadata": {},
   "source": [
    "### Question 11: Tasting and preparing the ingredients (univariate analysis) <a class=\"anchor\" id=\"question11\"></a>\n",
    "Do an univariate analysis for each variable you have chosen (outcome variable, main explanatory variable and explanatory variable for heterogeneity):\n",
    "- Prepare the variable, for example see if you need to transform the data further, i.e. log-transform, define a categorical variable, deal with outliers, etc.\n",
    "- Understand the nature of the variable, i.e. continuous, categorical, binary, etc., which then allows to pick the right statistical tool in the bivariate analysis.\n",
    "- Get an idea of the variable's behavior across time and space.\n",
    "\n",
    "Describe these steps and the conclusions you can draw with the help of histograms, tables, maps and line graphs. **(3 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 11\n",
    "# This Climate Change Tax is a variable i have investigated a lot, and i do not find any particular outliers. Its a continuous variable.\n",
    "tax_co2_cc_df.oecd_cctr_gdp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c259b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Co2 per capita is a variable i also have looked a lot into. The nature of it is continuous.\n",
    "tax_co2_df.co2_per_capita.describe()\n",
    "# Just checking for any anomalies or sudden changes.\n",
    "tax_co2_df[tax_co2_df.co2_per_capita > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a deeper understanding of the changes from year to year, we can use the method change() \n",
    "# to see the percentage change from year to year\n",
    "# \n",
    "# This will catch any sudden and possibly wrong changes\n",
    "# These rows represent the first year these countries registered co2\n",
    "# as the definition of the change() function states that if the prior value is NaN\n",
    "# So should the change be. I'm a bit puzzled why these aren't NaN...\n",
    "# But i will keep these in mind when plotting.\n",
    "\n",
    "df_co2_final.co2_per_capita.pct_change().describe()\n",
    "df_co2_final[df_co2_final.co2_per_capita.pct_change() > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the values for Climate challenge Issues. Score with comma from 0-100.\n",
    "climate_challenge_clean.describe()\n",
    "climate_challenge_clean.epi_cch.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529cfe2f",
   "metadata": {},
   "source": [
    "#### To sum up so far and the variables i have:\n",
    "\n",
    "- Climate Change Tax % of GDP (`oecd_cctr_gdp`) : continuous\n",
    "- Climate Challenge (`epi_cch`) : continuous\n",
    "- Co2 per capita (`co2_per_capita`) : continuous\n",
    "\n",
    "\n",
    "### Now i want to visualize the three variables i have, to gain a general outlook before going into the bivariate analysis.\n",
    "\n",
    "#### I will start by visualizing and exploring the data of `CO2 Emissions per capita`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tax_co2_df, y=\"co2_per_capita\", x=\"year\",\n",
    "                 size=\"co2_per_capita\", color=\"country\", hover_name=\"country\",\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"CO2 emission per capita per country\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"CO2 emission per capita (tons)\",\n",
    "    legend_title=\"Countries\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=12,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318947aa",
   "metadata": {},
   "source": [
    "I can see that Brunei has huge fluctuations. It has so in the source code as well, but i think these data-points will influence my results in a too strong way, so i will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Brunei\n",
    "\n",
    "brunei_index = tax_co2_df[tax_co2_df.country == 'Brunei'].index\n",
    "tax_co2_df.drop(index=brunei_index, inplace=True)\n",
    "len(tax_co2_df[tax_co2_df.country == 'Brunei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now - without Brunei\n",
    "\n",
    "fig = px.scatter(tax_co2_df, y=\"co2_per_capita\", x=\"year\",\n",
    "                 size=\"co2_per_capita\", color=\"country\", hover_name=\"country\",\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"CO2 emission per capita per country\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"CO2 emission per capita (tons)\",\n",
    "    legend_title=\"Countries\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=12,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a53f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.choropleth(tax_co2_df.sort_values('year', ascending=True), title='CO2 emission per capita per country per year',\n",
    "                    locations=\"iso3\", color=\"co2_per_capita\", hover_name=\"country\", animation_frame=\"year\", range_color=[0.01, 10])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(tax_co2_df, path=[px.Constant('world'), 'country'], values='co2_per_capita',\n",
    "                 color='co2_per_capita', hover_data=['country'], title='Total CO2 Emissions per capita per country')\n",
    "fig.update_layout(margin=dict(t=50, l=25, r=25, b=25))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(climate_tax_df, y=\"oecd_cctr_gdp\", x=\"year\",\n",
    "                 size='oecd_cctr_gdp', color=\"country\", hover_name=\"country\", range_x=[1999, 2020],\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Change Tax % of GDP\",\n",
    "    xaxis_title=\"Year\",\n",
    "    yaxis_title=\"% of GDP\",\n",
    "    legend_title=\"Countries\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=12,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b603fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.choropleth(climate_tax_df.sort_values('year', ascending=True), title='Climate Change Tax % of GDP',\n",
    "                    locations='iso3', color='oecd_cctr_gdp', hover_name='country', animation_frame='year', range_color=[0.01, 5])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9e83e",
   "metadata": {},
   "source": [
    "### Now i will move on to the Climate Change Issue data, and see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(climate_challenge_clean.sort_values('epi_cch', ascending=True), y=\"epi_cch\", x='country',\n",
    "             color=\"country\", hover_name=\"country\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Change Issue\",\n",
    "    showlegend=False,\n",
    "    xaxis_title=\"Cuuntry\",\n",
    "    yaxis_title=\"Climate Change Issue Score\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=10,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac138c40",
   "metadata": {},
   "source": [
    "### To log or not to log?\n",
    "\n",
    "Now i will look into how symmetricly the data is distributed. We can do this by reviewing data skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to address if skewness is in the range -3 to 3\n",
    "def skew_within_range(s):\n",
    "    if int(s) in range(-3, 3):\n",
    "        return 'Yes'\n",
    "    return 'No'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with the CO2 data\n",
    "co2_skew = skew(tax_co2_df[\"co2_per_capita\"], nan_policy=\"omit\")\n",
    "c02_hist = px.histogram(data_frame=tax_co2_df, title=\"CO2 skewness: {:.2f}\".format(co2_skew),\n",
    "                        x='co2_per_capita', marginal=\"box\", text_auto=True)\n",
    "c02_hist.show()\n",
    "print(f'Skew within range: {skew_within_range(co2_skew)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad75a3",
   "metadata": {},
   "source": [
    "The Co2 data is heavily right skewed. But this is expected as are where fewer early recordings, and these were the \"small\" numbers. Recent and additionally is more dense data and of larger magnitude. I'm in the end going to aggregate this data, so i will not log transform it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1887c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Continuing with the Climate Change Tax data\n",
    "tax_skew = skew(tax_co2_df[\"oecd_cctr_gdp\"], nan_policy=\"omit\")\n",
    "tax_hist = px.histogram(data_frame=tax_co2_df, title=\"Tax skewness: {:.2f}\".format(tax_skew),\n",
    "                        x='co2_per_capita', marginal=\"box\", text_auto=True)\n",
    "tax_hist.show()\n",
    "print(f'Skew within range: {skew_within_range(tax_skew)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4eb0b",
   "metadata": {},
   "source": [
    "### The Climate Challenge Issue Category does not represent what i thought i did...\n",
    "\n",
    "My initial interpretation of the `Climate Challenge Issue Score (epi_cch)` was that it represented the overall issues a country faces in regards to climate change. I got curious if this was correct after seeing the plot above. It did not make sense that Denmark (as one example) faces a lot of challenges - it may indeed have an overall low elevation above sea level. So i had to read the documentation again, and then again. The Climate Change Issue - is describing something completely different.\n",
    "\n",
    "Definition:\n",
    "> The Environmental Performance Index provides a ranking that shines light on how each country manages environmental issues. `The Climate Challenge Issue Category` (a sub-category of the EPI) consists of 8 indicators and how the country has dealt with these in the time range from approx 2001-2017. \n",
    "\n",
    " I could have changed the value, pivoted the whole hypothesis and research question, but i think the mistake i made here represents how it is to deal with large datasets and complicated definitions. So i will keep transparency, incorporate my mistake - and take the implications it gives.\n",
    "\n",
    " This means, as variable for heterogeneity it does not work as well as intended. There will be some correlation between how much a country taxes climate change and its given score for how well it has handled climate change (represented by the 8 indicators in `epi_cch`). But i can use this variable to see if the tax is actually leading to effective measures taken to combat climate change! So in the sense, im deviating a bit - but the variable does give some more insight into the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1ad4a-70fc-4f39-bffb-cf10dd93205f",
   "metadata": {},
   "source": [
    "### Question 12: Cooking the ingredients together (bivariate analysis) <a class=\"anchor\" id=\"question12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0c658-8c22-4bb0-b1ef-4b5860f6cc31",
   "metadata": {},
   "source": [
    "Considering the \"nature\" of your variables (continuous, categorical, binary, etc.), pick the right tool / tools for a preliminary bivariate analysis, i.e. correlation tables, bar/line graphs, scatter plots, etc. Use these tools to describe your preliminary bivariate analysis and your findings. **(3 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf4ec4",
   "metadata": {},
   "source": [
    "Answer 12:\n",
    "\n",
    "1. Firstly - I want to aggregate the `CO2 emissions per capita` (by sum/total) to only contain one value per country. As CO2 has an atmospheric lifetime estimated in the range between 5 and 1000 years (NASA: 300-1000, IPCC: 5-200) - CO2 emissions has a long-term effect!\n",
    "2. Secondly - I want to take to aggregate `Climate change tax` by  averaging each countries values. I believe this gives the most accurate picture.\n",
    "3. Thirdly - I will merge in `The Climate Change Issue`, the second explanatory variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39debae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean of climate change tax\n",
    "tax_mean_df = tax_co2_df.groupby(['iso3', 'country'])['oecd_cctr_gdp'].mean().reset_index(name='oecd_cctr_gdp_mean')\n",
    "\n",
    "# Calculating the sum of co2 emissions\n",
    "co2_sum_df = tax_co2_df.groupby(['iso3', 'country'])['co2_per_capita'].sum().reset_index(name='co2_per_capita_total')\n",
    "\n",
    "# Cleaning\n",
    "tax_mean_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2572d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging tax_mean and co2_sum\n",
    "tax_co2_agg_df = pd.merge(left=tax_mean_df, right=co2_sum_df, how='left', validate='1:1')\n",
    "tax_co2_agg_df\n",
    "\n",
    "# Merging tax_co2_agg and climate_challenge_issue\n",
    "tax_co2_cc_df = pd.merge(left=tax_co2_agg_df, right=climate_challenge_clean, how='left', validate='1:1')\n",
    "tax_co2_cc_df\n",
    "\n",
    "# Cleaning\n",
    "tax_co2_cc_df_clean = tax_co2_cc_df.copy()\n",
    "tax_co2_cc_df_clean.dropna(inplace=True)\n",
    "tax_co2_cc_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909deb66",
   "metadata": {},
   "source": [
    "### Geography\n",
    "\n",
    "As some countries were dropped, i think its important to again have a look at the geographical distribution of our aggregated data. The climate change tax variable, is derived from OECD - impacting exactly this scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09606aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.choropleth(tax_co2_cc_df_clean, title='Geographical distribution',\n",
    "                    locations='iso3', color='country', hover_name='country')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135bbbc",
   "metadata": {},
   "source": [
    "We are missing United Kingdom, USA, Brazil and Russia (among others) - big polluters that may influence my findings. OECD countries are heavily represented - this may also influence my results as they (aim) to work towards a sustainable world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67088fdf",
   "metadata": {},
   "source": [
    "### Again... To log or not to log\n",
    "\n",
    "Now that i have aggregated the data, its time to investigate the skewness again. I found a plot i think illustrated how the data is distributed in a nice way. I also wrote a simple function checking if the skewness is within the range of -3 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating skewness for aggregated data\n",
    "# Total Co2 per capita\n",
    "co2_skew = skew(tax_co2_cc_df_clean[\"co2_per_capita_total\"], nan_policy=\"omit\")\n",
    "co2_hist = px.histogram(data_frame=tax_co2_cc_df_clean, title=\"Total CO2 per capita skewness: {:.2f}\".format(co2_skew),\n",
    "                        x='co2_per_capita_total', marginal=\"box\", text_auto=True)\n",
    "co2_hist.show()\n",
    "print(f'Skew within range: {skew_within_range(co2_skew)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Climate Change Tax\n",
    "cctax_skew = skew(tax_co2_cc_df_clean[\"oecd_cctr_gdp_mean\"], nan_policy=\"omit\")\n",
    "cctax_hist = px.histogram(data_frame=tax_co2_cc_df_clean, title=\"Mean Climate Change Tax skewness: {:.2f}\".format(cctax_skew),\n",
    "                        x='oecd_cctr_gdp_mean', marginal=\"box\", text_auto=True)\n",
    "cctax_hist.show()\n",
    "print(f'Skew within range: {skew_within_range(cctax_skew)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df622617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Climate Change Tax\n",
    "epi_cch_skew = skew(tax_co2_cc_df_clean[\"epi_cch\"], nan_policy=\"omit\")\n",
    "epi_cch_hist = px.histogram(data_frame=tax_co2_cc_df_clean, title=\"Climate Change Issue skewness: {:.2f}\".format(epi_cch_skew),\n",
    "                        x='epi_cch', marginal=\"box\", text_auto=True)\n",
    "epi_cch_hist.show()\n",
    "print(f'Skew within range: {skew_within_range(epi_cch_skew)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf39fc1",
   "metadata": {},
   "source": [
    "### Lets visualize! \n",
    "\n",
    "Now that we have checked for skewness, its time to make some plots. The first plot shows my outcome variable : **Carbon Tax** vs the first explanatory variable : **Total CO2 emission**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c0962-c661-4649-b8f3-e721e7ef66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tax_co2_cc_df_clean.sort_values('co2_per_capita_total', ascending=True), y=\"oecd_cctr_gdp_mean\", x=\"co2_per_capita_total\",\n",
    "                 size=\"co2_per_capita_total\", color=\"country\", hover_name=\"country\", hover_data={'co2_per_capita_total': ':.1f', 'oecd_cctr_gdp_mean': ':.1f'},\n",
    "                 labels={'oecd_cctr_gdp_mean': 'Mean CC Tax (% of GDP)',\n",
    "                         'co2_per_capita_total': 'Total C02 Emission per capita'},\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Tax of GDP vs Total C02 emissions per capita\",\n",
    "    xaxis_title=\"Total CO2 per capita (tons)\",\n",
    "    yaxis_title=\"Avg Climate Tax % of GDP(2000-2017)\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=12,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b2f36",
   "metadata": {},
   "source": [
    "My second plot, shows the same data but with a best fitting OLS line - highligting the positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tax_co2_cc_df_clean.sort_values('co2_per_capita_total', ascending=True), y=\"oecd_cctr_gdp_mean\", x=\"co2_per_capita_total\",\n",
    "                 size=\"co2_per_capita_total\", color=\"oecd_cctr_gdp_mean\", hover_name=\"country\", trendline='ols', hover_data={'co2_per_capita_total': ':.1f', 'oecd_cctr_gdp_mean': ':.1f'},\n",
    "                 labels={'oecd_cctr_gdp_mean': 'Mean CC Tax (% GDP)',\n",
    "                         'co2_per_capita_total': 'Total C02 Emission per capita'},\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Change Tax % of GDP vs Total C02 emissions per capita - with OLS trendline\",\n",
    "    xaxis_title=\"Total CO2 per capita (tons)\",\n",
    "    yaxis_title=\"Avg Climate Tax % of GDP(2000-2017)\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=10,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "results = px.get_trendline_results(fig)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16186302",
   "metadata": {},
   "source": [
    "My third scatter plot, includes the second explanatory varaible - **Climate Change Issue** (from the Environmental Performance Index). Be observant of the new color shading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tax_co2_cc_df_clean.sort_values('co2_per_capita_total', ascending=True), y=\"oecd_cctr_gdp_mean\", x=\"co2_per_capita_total\",\n",
    "                 size=\"co2_per_capita_total\", color=\"epi_cch\", hover_name=\"country\", trendline='ols', hover_data={'co2_per_capita_total': ':.1f', 'oecd_cctr_gdp_mean': ':.1f'},\n",
    "                 labels={'oecd_cctr_gdp_mean': 'Mean CC Tax (% GDP)',\n",
    "                         'co2_per_capita_total': 'Total C02 Emission per capita'},\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Change Tax % of GDP vs Total C02 emissions per capita - with OLS trendline\",\n",
    "    xaxis_title=\"Total CO2 per capita (tons)\",\n",
    "    yaxis_title=\"Avg Climate Tax % of GDP(2000-2017)\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=10,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "results = px.get_trendline_results(fig)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832263d",
   "metadata": {},
   "source": [
    "We can see that the darker/purple colors are usually located below the line. And the light orange/yellow colors are above the line. What does this mean? As mentioned earlier my second explanatory variable may not have been working so well for heterogeneity, as i misinterpreted its definition. But it may give an indication on wether a country is successful at turning climate change tax into effective measures. Either way - i will investigate the correlation between my outcome variable : **Climate Change Tax** and the second explanatory variable : **Climate Change Issue**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_co2_cc_df_clean[['oecd_cctr_gdp_mean', 'epi_cch']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155eaef",
   "metadata": {},
   "source": [
    "The correlation of `0.65` is quite strong - the same impression i got from looking at the scatter plot. So how well a country performs on the climate change issue is a strong predictor of how much a country taxes climate change. Or is it the way around?... They both describe the same scope, so it is natural that they are tightly coupled. This is what i expected - but again not my initial intention. We can visualize the relationship clearer with the scatterplot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(tax_co2_cc_df_clean, y=\"oecd_cctr_gdp_mean\", x=\"epi_cch\",\n",
    "                 size=\"oecd_cctr_gdp_mean\", color=\"epi_cch\", hover_name=\"country\", trendline='ols', hover_data={'epi_cch': ':.1f', 'oecd_cctr_gdp_mean': ':.1f'},\n",
    "                 labels={'oecd_cctr_gdp_mean': 'Mean CC Tax (% GDP)',\n",
    "                         'epi_cch': 'Climate Change Issue'},\n",
    "                 log_x=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Climate Change Tax % of GDP vs Climate Change Issue - with OLS trendline\",\n",
    "    xaxis_title=\"Climate Change Issue (EPI score)\",\n",
    "    yaxis_title=\"Avg Climate Tax % of GDP(2000-2017)\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=10,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(results.px_fit_results.iloc[0].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0a05d-004a-42f3-b472-b7a808cd0dc1",
   "metadata": {},
   "source": [
    "### Question 13: Tasting the new recipe (conclusion) <a class=\"anchor\" id=\"question13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b861d-d4d5-42b1-94ad-5aa33f9bf7a2",
   "metadata": {},
   "source": [
    "Explain what you learned, the problem faced, what would you do next (you can suggest other data you would like to have etc). **(2 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f29308",
   "metadata": {},
   "source": [
    "Answer 13:\n",
    "\n",
    "### Learnings and Problems\n",
    "\n",
    "My second explanatory variable did not impose the heterogeneity I wanted. This was due to documentation misreading. I acknowledge that I'm not the first to do so. Evidently, through the error I found in the QOG database, they had misunderstood the epi_cch score. They used `Tax revenue, % of total environmentally related tax revenue` instead of `Climate change-related tax revenue as % of GDP`. I have learned that no perfect dataset exists. If I wanted to stay with my hypothesis and the variables I had chosen, I needed to get the correct data. I did and quickly understood why the QoG researchers were wrong. This was a massive dataset (> 70MB) with many subcategories in countless domains. Luckily I found what I was searching for and could continue.\n",
    "\n",
    "Some of the problems, issues, and learnings I've met and gained during this exercise were:\n",
    "\n",
    "- It is hard to work with data from different years in one dataframe where NaNs are expected\n",
    "- Interpreting definitions can cause problems\n",
    "- Keeping track of all the columns and their respective names is hard!\n",
    "- Naming conventions are fundamental. I need to be more consistent at this. E.g., always use df first vs. last in a dataframe declaration. Note to self: all \"final\" dataframes should end with `_final`\n",
    "- Cleaning data takes time\n",
    "- Finding the perfect variable for your hypothesis is very hard (impossible?)\n",
    "- Manipulating a copy of the \"real\" dataframe before doing it on the original is vital\n",
    "- Splitting coding cells is efficient and saves a lot time\n",
    "- It's possible to spend an endless amount of time making plots pretty\n",
    "\n",
    "### Reflections and going further\n",
    "\n",
    "The general observation from the plots is that a positive correlation exists between the **total CO2 emissions per capita** and the **tax mean related to climate change in % of GDP** with a coefficient of 1.089. The statistical test done above emphasizes that 13.6% of the variance of the climate change tax (% of GDP) is explained by the variance of total Co2 emission. (R^2 of 0.136). Furthermore, it highlights a very low P value (<0) and an F-stat at 11.31. I will not go further into these statistical tests but focus on my interpretation of the data and plausible turns I could have taken. \n",
    "\n",
    "What does my outcome tell me? First of all - there may be several drivers explaining the positive correlation. Countries with high total CO2 emissions (FYI: intuitive reflection incoming) are usually countries with a lot of trade (i could look further into this) - that given, it is vital to have a common value-set to cooperate efficiently and with respect. And as climate change is a global problem, countries that neglect climate change could face difficulties trading proficiently  - and we could therefore see that this effect could collude with the relationship I found. A solution to this could be to use `% of GDP coming from trade` as a second or third explanatory variable.\n",
    "\n",
    "I introduced this exploratory part with the term climate responsibility. Can we call these countries climate responsible because of the positive correlation? No. I don't think so. First of all, taxes do not directly translate into being responsible. What does the taxes do? Are they effective at meeting climate change? My findings do not say anything about this. Additionally, being from Norway (with a total of 670 tons co2 per capita), rich oil countries are entirely independent of the oil they dig up and sell in statistics as these. Does to not burn to mean to not be responsible, even though you dug it and sold it?\n",
    "\n",
    "Another fundamental notion is that I could have chosen another explanatory value when I realized my wrongdoing. After studying the `QoG Codebook,` again, the `Total damage from natural disasters in USD (emdat_damage)` could have made a good variable for heterogeneity. A country facing many climate threats will consequently spend much money repairing damages from incidents, s.a., extreme weather. This variable describes the cost of natural disasters – and, therefore, indirectly, the burden of climate change. Lastly, as the USA, Great Britain, and Russia are some of the biggest polluters, I would use an outcome variable that includes these countries (but I wanted to avoid using the same value as Quentin). \n",
    "\n",
    "\n",
    "Thank you for making such a comprehensive, challenging, and fun assignment - I learned a lot!\n",
    "\n",
    "To shwocase and motivate my own progression with data science i made a portfolio hosted og GitHub. If you want, you can check it out at https://percw.github.io/. Its a work in progress, currently working on making it interactive with Plotply Dash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f5d6f",
   "metadata": {},
   "source": [
    "### Computing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc07146",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p jupyterlab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
